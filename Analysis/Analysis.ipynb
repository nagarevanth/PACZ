{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello i need a computer and flat screen moved the location is ebe only one computer and a flat screen needs to be moved to ebg the remaining flat screens should stay at the location ebe rc co thanks kevin moore please if at all possible let me know when this should take place\n",
      "6120\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "dataset_path = 'datasets/genz_emails_final_translated.csv'\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Split the data into 'up' and 'down' directions\n",
    "up_texts = df[df['Hierarchy_Label'] == 'Sender higher']['original'].tolist()\n",
    "down_texts = df[df['Hierarchy_Label'] == 'Recipient higher']['original'].tolist()\n",
    "\n",
    "\n",
    "def clean_email(text):\n",
    "    text = text.replace('\\n', ' ')              # Remove newlines\n",
    "    text = re.sub(r'\\d+', '', text)             # Remove numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)     # Remove special characters\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()    # Normalize whitespace\n",
    "    return text.lower()\n",
    "\n",
    "up_texts = [clean_email(text) for text in up_texts]\n",
    "down_texts = [clean_email(text) for text in down_texts]\n",
    "\n",
    "print(up_texts[0])\n",
    "\n",
    "# Extract n-grams\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 3), min_df=3)\n",
    "X_up = vectorizer.fit_transform(up_texts)\n",
    "X_down = vectorizer.transform(down_texts)\n",
    "phrases = vectorizer.get_feature_names_out()\n",
    "\n",
    "print(len(phrases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "def compute_log_odds(up_counts, down_counts, alpha=0.01):\n",
    "    # Add-one smoothing\n",
    "    up = np.array(up_counts) + 1\n",
    "    down = np.array(down_counts) + 1\n",
    "    total_up = up.sum()\n",
    "    total_down = down.sum()\n",
    "    \n",
    "    # Calculate log-odds ratio\n",
    "    log_odds = np.log((up / (total_up - up)) / (down / (total_down - down)))\n",
    "    return log_odds\n",
    "\n",
    "# Get counts\n",
    "up_counts = X_up.toarray().sum(axis=0)\n",
    "down_counts = X_down.toarray().sum(axis=0)\n",
    "\n",
    "# Compute log-odds\n",
    "log_odds_scores = compute_log_odds(up_counts, down_counts)\n",
    "\n",
    "# Top up and down phrases\n",
    "sorted_up = sorted(zip(phrases, log_odds_scores), key=lambda x: x[1], reverse=True)\n",
    "sorted_down = sorted(zip(phrases, log_odds_scores), key=lambda x: x[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top UPWARD phrases:\n",
      "corp legal department: 2.86\n",
      "department smith: 2.84\n",
      "department smith street: 2.84\n",
      "legal department smith: 2.84\n",
      "thanks ben: 2.73\n",
      "ebiz: 2.61\n",
      "this distribution: 2.61\n",
      "veronica: 2.48\n",
      "america corp legal: 2.46\n",
      "corp legal: 2.46\n",
      "best jeff: 2.44\n",
      "veronica espinoza: 2.41\n",
      "espinoza at: 2.33\n",
      "veronica espinoza at: 2.33\n",
      "couple of: 2.24\n",
      "regards delainey: 2.24\n",
      "report to: 2.24\n",
      "thomas: 2.24\n",
      "thanks kay: 2.19\n",
      "abx: 2.14\n",
      "amendments: 2.14\n",
      "at work: 2.14\n",
      "dial in: 2.14\n",
      "for other: 2.14\n",
      "the assembly: 2.14\n",
      "been sent: 2.04\n",
      "deposit: 2.04\n",
      "distribution please: 2.04\n",
      "forum: 2.04\n",
      "group that: 2.04\n",
      "not included: 2.04\n",
      "overview: 2.04\n",
      "people to: 2.04\n",
      "sara shackleton enron: 2.04\n",
      "shackleton enron: 2.04\n",
      "this distribution please: 2.04\n",
      "your group that: 2.04\n",
      "legal department: 2.02\n",
      "dperlinenroncom: 2.02\n",
      "dperlinenroncom phone: 2.02\n",
      "dperlinenroncom phone fax: 2.02\n",
      "houston texas dperlinenroncom: 2.02\n",
      "texas dperlinenroncom: 2.02\n",
      "texas dperlinenroncom phone: 2.02\n",
      "delainey: 1.98\n",
      "debra perlingiere: 1.92\n",
      "perlingiere: 1.92\n",
      "transport: 1.92\n",
      "wholesale services: 1.92\n",
      "add additional: 1.92\n",
      "\n",
      "Top DOWNWARD phrases:\n",
      "named: -1.98\n",
      "click here: -1.91\n",
      "user: -1.77\n",
      "the report: -1.77\n",
      "this request: -1.70\n",
      "have received this: -1.66\n",
      "click on: -1.58\n",
      "is now: -1.55\n",
      "received this: -1.55\n",
      "password: -1.51\n",
      "available for: -1.50\n",
      "act: -1.49\n",
      "tana: -1.48\n",
      "delivery: -1.46\n",
      "click: -1.44\n",
      "hpl: -1.43\n",
      "create: -1.43\n",
      "all of the: -1.41\n",
      "and other: -1.41\n",
      "below is: -1.41\n",
      "central time: -1.41\n",
      "increase: -1.41\n",
      "limit: -1.41\n",
      "louise: -1.41\n",
      "teco: -1.41\n",
      "please click: -1.39\n",
      "total: -1.35\n",
      "ahead: -1.34\n",
      "all your: -1.34\n",
      "invoice: -1.34\n",
      "outage: -1.34\n",
      "reviewed: -1.34\n",
      "future: -1.33\n",
      "you have received: -1.31\n",
      "products: -1.30\n",
      "the website: -1.30\n",
      "applications: -1.30\n",
      "currently: -1.29\n",
      "approval: -1.26\n",
      "click on the: -1.26\n",
      "interview: -1.26\n",
      "now available: -1.26\n",
      "co: -1.26\n",
      "large: -1.26\n",
      "attached the: -1.26\n",
      "information is: -1.26\n",
      "is copy: -1.26\n",
      "is copy of: -1.26\n",
      "real: -1.26\n",
      "to view: -1.26\n"
     ]
    }
   ],
   "source": [
    "print(\"Top UPWARD phrases:\")\n",
    "for phrase, score in sorted_up[:50]:\n",
    "    print(f\"{phrase}: {score:.2f}\")\n",
    "\n",
    "print(\"\\nTop DOWNWARD phrases:\")\n",
    "for phrase, score in sorted_down[:50]:\n",
    "    print(f\"{phrase}: {score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the location is ebe only one computer and a flat screen need to be moved to the spot the remaining flat screens should stay at the place rc co thanks kevin moore please if its all possible let me know when this should go down\n",
      "4774\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "dataset_path = 'datasets/genz_emails_final_translated.csv'\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Split the data into 'up' and 'down' directions\n",
    "up_texts = df[df['Hierarchy_Label'] == 'Sender higher']['generated'].tolist()\n",
    "down_texts = df[df['Hierarchy_Label'] == 'Recipient higher']['generated'].tolist()\n",
    "\n",
    "\n",
    "def clean_email(text):\n",
    "    text = text.replace('\\n', ' ')              # Remove newlines\n",
    "    text = re.sub(r'\\d+', '', text)             # Remove numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)     # Remove special characters\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()    # Normalize whitespace\n",
    "    return text.lower()\n",
    "\n",
    "up_texts = [clean_email(text) for text in up_texts]\n",
    "down_texts = [clean_email(text) for text in down_texts]\n",
    "\n",
    "print(up_texts[0])\n",
    "\n",
    "# Extract n-grams\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 3), min_df=3)\n",
    "X_up = vectorizer.fit_transform(up_texts)\n",
    "X_down = vectorizer.transform(down_texts)\n",
    "phrases = vectorizer.get_feature_names_out()\n",
    "\n",
    "print(len(phrases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "def compute_log_odds(up_counts, down_counts, alpha=0.01):\n",
    "    # Add-one smoothing\n",
    "    up = np.array(up_counts) + 1\n",
    "    down = np.array(down_counts) + 1\n",
    "    total_up = up.sum()\n",
    "    total_down = down.sum()\n",
    "    \n",
    "    # Calculate log-odds ratio\n",
    "    log_odds = np.log((up / (total_up - up)) / (down / (total_down - down)))\n",
    "    return log_odds\n",
    "\n",
    "# Get counts\n",
    "up_counts = X_up.toarray().sum(axis=0)\n",
    "down_counts = X_down.toarray().sum(axis=0)\n",
    "\n",
    "# Compute log-odds\n",
    "log_odds_scores = compute_log_odds(up_counts, down_counts)\n",
    "\n",
    "# Top up and down phrases\n",
    "sorted_up = sorted(zip(phrases, log_odds_scores), key=lambda x: x[1], reverse=True)\n",
    "sorted_down = sorted(zip(phrases, log_odds_scores), key=lambda x: x[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top UPWARD phrases:\n",
      "department smith: 2.83\n",
      "legal department smith: 2.83\n",
      "corp legal department: 2.80\n",
      "department smith street: 2.80\n",
      "thanks ben: 2.54\n",
      "wholesale services: 2.47\n",
      "dperlinenroroncom: 2.43\n",
      "dperlinenroroncom phone: 2.43\n",
      "dperlinenroroncom phone fax: 2.43\n",
      "houston texas dperlinenroroncom: 2.43\n",
      "texas dperlinenroroncom: 2.43\n",
      "texas dperlinenroroncom phone: 2.43\n",
      "america corp legal: 2.40\n",
      "corp legal: 2.40\n",
      "best jeff: 2.40\n",
      "enron wholesale: 2.31\n",
      "enron wholesale services: 2.31\n",
      "form of: 2.23\n",
      "peeps: 2.23\n",
      "eba: 2.13\n",
      "eba houston: 2.13\n",
      "get copy: 2.13\n",
      "smith street eba: 2.13\n",
      "street eba: 2.13\n",
      "street eba houston: 2.13\n",
      "thomas: 2.13\n",
      "veronica: 2.13\n",
      "thanks kay: 2.08\n",
      "annex: 2.03\n",
      "around pm: 2.03\n",
      "assuming: 2.03\n",
      "deposit: 2.03\n",
      "get copy of: 2.03\n",
      "lowkey looking: 2.03\n",
      "regards delainey: 2.03\n",
      "report to: 2.03\n",
      "sara shackleton enron: 2.03\n",
      "shackleton enron: 2.03\n",
      "this distribution: 2.03\n",
      "veronica espinoza: 2.03\n",
      "delainey: 1.97\n",
      "legal department: 1.95\n",
      "debra: 1.91\n",
      "phillip: 1.91\n",
      "wholesale: 1.91\n",
      "abx: 1.91\n",
      "add more: 1.91\n",
      "add more peeps: 1.91\n",
      "amendments: 1.91\n",
      "at work: 1.91\n",
      "\n",
      "Top DOWNWARD phrases:\n",
      "delivery: -1.91\n",
      "total: -1.84\n",
      "account: -1.71\n",
      "create: -1.59\n",
      "and take: -1.56\n",
      "live on: -1.56\n",
      "this request: -1.56\n",
      "questions hit me: -1.53\n",
      "currently: -1.51\n",
      "hit the: -1.51\n",
      "password: -1.47\n",
      "products: -1.47\n",
      "corporate: -1.45\n",
      "stock: -1.45\n",
      "requested: -1.44\n",
      "approval: -1.42\n",
      "this email: -1.42\n",
      "central time: -1.42\n",
      "this message: -1.40\n",
      "click: -1.40\n",
      "staff: -1.39\n",
      "status: -1.39\n",
      "intended: -1.37\n",
      "hit up the: -1.33\n",
      "on it: -1.33\n",
      "inc: -1.27\n",
      "during the: -1.27\n",
      "lowkey trying: -1.27\n",
      "lowkey trying to: -1.27\n",
      "not the: -1.27\n",
      "reviewed: -1.27\n",
      "space: -1.27\n",
      "click on: -1.20\n",
      "sitara: -1.20\n",
      "action: -1.18\n",
      "browser: -1.18\n",
      "enpower: -1.18\n",
      "in and: -1.18\n",
      "jan: -1.18\n",
      "louise: -1.18\n",
      "met: -1.18\n",
      "real: -1.18\n",
      "receive: -1.18\n",
      "process: -1.17\n",
      "order: -1.16\n",
      "above: -1.15\n",
      "up thanks: -1.15\n",
      "weekly: -1.15\n",
      "live: -1.14\n",
      "el paso: -1.13\n"
     ]
    }
   ],
   "source": [
    "print(\"Top UPWARD phrases:\")\n",
    "for phrase, score in sorted_up[:50]:\n",
    "    print(f\"{phrase}: {score:.2f}\")\n",
    "\n",
    "print(\"\\nTop DOWNWARD phrases:\")\n",
    "for phrase, score in sorted_down[:50]:\n",
    "    print(f\"{phrase}: {score:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
