{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eef30ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 23:19:51.596891: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746640191.610485   17791 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746640191.614468   17791 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-07 23:19:51.631839: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            original  \\\n",
      "0  Hello ,\\n\\nI need a computer and flat screen m...   \n",
      "1  Please disregard to prior version and use this...   \n",
      "2  \\n\\t [IMAGE] \\t\\n\\tThanksgiving is just around...   \n",
      "3  The PRELIMINARY Violation Memos for 11/16/01 h...   \n",
      "4  Start Date: 3/30/01; HourAhead hour: 24;  No a...   \n",
      "\n",
      "                                           generated   Hierarchy_Label  \n",
      "0  Hello,\\n\\nI'm low-key in need of a computer an...     Sender higher  \n",
      "1  Lowkey, forget the old one and vibe with this ...     Sender higher  \n",
      "2  Thanksgiving is lowkey right around the corner...  Recipient higher  \n",
      "3  The lowkey preliminary violation memos for 11/...  Recipient higher  \n",
      "4  Start Date: 3/30/01; HourAhead hour: 24; No ex...     Similar level  \n",
      "Index(['original', 'generated', 'Hierarchy_Label'], dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2503 entries, 0 to 2502\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   original         2503 non-null   object\n",
      " 1   generated        2503 non-null   object\n",
      " 2   Hierarchy_Label  2503 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 58.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "\n",
    "# Load the CSV\n",
    "df = pd.read_csv('datasets/genz_emails_final.csv')\n",
    "# drop the id column and save this as genz_data_final.csv\n",
    "df = df.drop(columns=['id'])\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "df.to_csv('datasets/genz_data_final.csv', index=False)\n",
    "print(df.head())\n",
    "print(df.columns)\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1adcfac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Check for CUDA\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "940a44d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the data\n",
    "df = pd.read_csv('datasets/genz_data_final.csv')\n",
    "# add all the rows present in datasets/genz_data.csv to the above df\n",
    "df_additional = pd.read_csv('datasets/genz_data.csv')\n",
    "df = pd.concat([df, df_additional], ignore_index=True)\n",
    "# Basic text preprocessing\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):\n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        # Replace multiple spaces with a single space\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        # Remove special characters but keep basic punctuation\n",
    "        text = re.sub(r'[^\\w\\s.,!?;:\\'\"-]', '', text)\n",
    "        return text.strip()\n",
    "    return \"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a926a80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples: 4902\n",
      "\n",
      "Original vs Gen Z Style (first 3 examples):\n",
      "\n",
      "Original: hello , i need a computer and flat screen moved. the location is eb3240e. only- one computer and a f...\n",
      "Gen Z: hello, i'm low-key in need of a computer and flat screen moved, tbh. the spot is eb3240e, fyi. just ...\n",
      "\n",
      "Original: please disregard to prior version and use this one....\n",
      "Gen Z: lowkey, forget the old one and vibe with this new version, aight?...\n",
      "\n",
      "Original: image thanksgiving is just around the corner! thanksgiving special order now and save 5 off or 10 of...\n",
      "Gen Z: thanksgiving is lowkey right around the corner! thanksgiving special order now and cop a 5 discount ...\n",
      "\n",
      "Training examples: 4411\n",
      "Validation examples: 491\n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing\n",
    "df['original_processed'] = df['original'].apply(preprocess_text)\n",
    "df['generated_processed'] = df['generated'].apply(preprocess_text)\n",
    "\n",
    "# Display sample data\n",
    "print(f\"Total examples: {len(df)}\")\n",
    "print(\"\\nOriginal vs Gen Z Style (first 3 examples):\")\n",
    "for i in range(3):\n",
    "    print(f\"\\nOriginal: {df['original_processed'].iloc[i][:100]}...\")\n",
    "    print(f\"Gen Z: {df['generated_processed'].iloc[i][:100]}...\")\n",
    "\n",
    "# Split the data\n",
    "train_df, val_df = train_test_split(df, test_size=0.1, random_state=42)\n",
    "print(f\"\\nTraining examples: {len(train_df)}\")\n",
    "print(f\"Validation examples: {len(val_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a594c322",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenZStyleDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_source_length=512, max_target_length=512):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_source_length = max_source_length\n",
    "        self.max_target_length = max_target_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        source_text = self.data['original_processed'].iloc[index]\n",
    "        target_text = self.data['generated_processed'].iloc[index]\n",
    "        \n",
    "        # Prepare the inputs for the model\n",
    "        source_encoding = self.tokenizer(\n",
    "            \"translate to GenZ style: \" + source_text,\n",
    "            max_length=self.max_source_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        target_encoding = self.tokenizer(\n",
    "            target_text,\n",
    "            max_length=self.max_target_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        input_ids = source_encoding[\"input_ids\"].squeeze()\n",
    "        attention_mask = source_encoding[\"attention_mask\"].squeeze()\n",
    "        labels = target_encoding[\"input_ids\"].squeeze()\n",
    "        # Replace padding token id with -100 so it's ignored in loss calculation\n",
    "        labels[labels == self.tokenizer.pad_token_id] = -100\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"labels\": labels\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2864ac12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "/home/revanthsnr/main_venv/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load T5 model and tokenizer\n",
    "model_name = \"t5-small\"  # You can use \"t5-base\" for better performance\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = GenZStyleDataset(train_df, tokenizer)\n",
    "val_dataset = GenZStyleDataset(val_df, tokenizer)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=4)\n",
    "\n",
    "# Set up the optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=5e-4)\n",
    "total_steps = len(train_dataloader) * 5  # 5 epochs\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60872c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train(model, dataloader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\")\n",
    "    for batch in progress_bar:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\"loss\": loss.item()})\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# Function to generate Gen Z style text\n",
    "def generate_genz_text(text, model, tokenizer, device, max_length=512):\n",
    "    model.eval()\n",
    "    \n",
    "    # Prepare input\n",
    "    input_text = text\n",
    "    input_ids = tokenizer(\n",
    "        input_text,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).input_ids.to(device)\n",
    "    \n",
    "    # Generate output\n",
    "    outputs = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        max_length=max_length,\n",
    "        num_beams=5,\n",
    "        no_repeat_ngram_size=2,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    \n",
    "    # Decode output\n",
    "    genz_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    return genz_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d920b855",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Training loop\n",
    "# num_epochs = 5\n",
    "# best_val_loss = float('inf')\n",
    "\n",
    "# print(\"\\nStarting training...\")\n",
    "# for epoch in range(num_epochs):\n",
    "#     print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "    \n",
    "#     # Train\n",
    "#     train_loss = train(model, train_dataloader, optimizer, scheduler, device)\n",
    "#     print(f\"Training loss: {train_loss:.4f}\")\n",
    "    \n",
    "#     # Evaluate\n",
    "#     val_loss = evaluate(model, val_dataloader, device)\n",
    "#     print(f\"Validation loss: {val_loss:.4f}\")\n",
    "    \n",
    "#     # Save the best model\n",
    "#     if val_loss < best_val_loss:\n",
    "#         best_val_loss = val_loss\n",
    "#         # Create directory if it doesn't exist\n",
    "#         os.makedirs('models', exist_ok=True)\n",
    "#         torch.save(model.state_dict(), 'models/genz_t5_model_new.pt')\n",
    "#         print(\"Best model saved!\")\n",
    "\n",
    "# # Load the best model\n",
    "# model.load_state_dict(torch.load('models/genz_t5_model_new.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8b22096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test the model on some examples\n",
    "# test_examples = [\n",
    "#     \"avoid majority despite stock mission idea action. rise adult dream way. job organization forget world guess off. property thank need manage later reason. pressure near lose organization. close admit popular option. understand reveal follow ask body. range final seven fall\",\n",
    "#     \"Hello, I wanted to inform you about our upcoming meeting next Tuesday.\",\n",
    "#     \"The project deadline has been extended until next Friday.\",\n",
    "#     \"Thank you for your prompt response to my email.\",\n",
    "#     \"religious region never happy main. piece us step wonder teach. management seek military alone environment budget. bit his but phone. whether of season road herself system. court better national tonight. state indicate house too test. ahead capital change.\"\n",
    "# ]\n",
    "\n",
    "# print(\"\\nTesting the model with examples:\")\n",
    "# for text in test_examples:\n",
    "#     genz_text = generate_genz_text(text, model, tokenizer, device)\n",
    "#     print(f\"\\nOriginal: {text}\")\n",
    "#     print(f\"Gen Z: {genz_text}\")\n",
    "\n",
    "# # Save the tokenizer for later use\n",
    "# tokenizer.save_pretrained('models/genz_t5_tokenizer_new')\n",
    "\n",
    "# print(\"\\nTraining complete! Model and tokenizer saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12dcc5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a simple function to use the model\n",
    "# def translate_to_genz(input_text):\n",
    "#     \"\"\"\n",
    "#     Function to translate normal text to Gen Z style using the trained model.\n",
    "#     \"\"\"\n",
    "#     return generate_genz_text(input_text, model, tokenizer, device)\n",
    "\n",
    "# # Example of how to use the function\n",
    "# print(\"\\nExample usage of the translation function:\")\n",
    "# example = \"This is a formal business communication regarding your recent purchase.\"\n",
    "# genz_result = translate_to_genz(example)\n",
    "# print(f\"Original: {example}\")\n",
    "# print(f\"Gen Z: {genz_result}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c6bde67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved complete model package for easy loading!\n",
      "\n",
      "Example of loading and using the saved model:\n",
      "# Code to load and use the model:\n",
      "model, tokenizer = load_genz_model()\n",
      "input_text = 'Your formal text here'\n",
      "genz_text = generate_genz_text(input_text, model, tokenizer, device)\n",
      "print(genz_text)\n"
     ]
    }
   ],
   "source": [
    "# Save both model and tokenizer in a single pickle file for easier loading\n",
    "model_package = {\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'tokenizer_name': model_name\n",
    "}\n",
    "\n",
    "with open('models/genz_t5_complete.pkl', 'wb') as f:\n",
    "    pickle.dump(model_package, f)\n",
    "\n",
    "print(\"\\nSaved complete model package for easy loading!\")\n",
    "\n",
    "# Usage example for loading the saved model\n",
    "def load_genz_model():\n",
    "    \"\"\"\n",
    "    Load the trained Gen Z translator model and tokenizer.\n",
    "    \"\"\"\n",
    "    with open('models/genz_t5_complete.pkl', 'rb') as f:\n",
    "        model_package = pickle.load(f)\n",
    "    \n",
    "    # Load tokenizer and model\n",
    "    tokenizer = T5Tokenizer.from_pretrained(model_package['tokenizer_name'])\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_package['tokenizer_name'])\n",
    "    model.load_state_dict(model_package['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "# Example to show how to load and use the model\n",
    "print(\"\\nExample of loading and using the saved model:\")\n",
    "print(\"# Code to load and use the model:\")\n",
    "print(\"model, tokenizer = load_genz_model()\")\n",
    "print(\"input_text = 'Your formal text here'\")\n",
    "print(\"genz_text = generate_genz_text(input_text, model, tokenizer, device)\")\n",
    "print(\"print(genz_text)\")\n",
    "\n",
    "\n",
    "# load the model and tokenizer\n",
    "model, tokenizer = load_genz_model()\n",
    "# Example usage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7bf28d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dad, I was talking with Kathleen this weekend and she had some ideas and suggestions about Enron.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Dad, I was talking with Kathleen this weekend and she had some ideas and suggestions about Enron. I asked her to put them in writing so that I could share them with you.\"\n",
    "genz_text = generate_genz_text(input_text, model, tokenizer, device)\n",
    "print(genz_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5684c48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating rows:   0%|          | 10/2503 [00:04<16:51,  2.46it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved modified DataFrame to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_csv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Replace the generated column in the original CSV\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[43mreplace_generated_column\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdatasets/genz_emails_final.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdatasets/genz_emails_final_translated.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 18\u001b[0m, in \u001b[0;36mreplace_generated_column\u001b[0;34m(input_csv, output_csv)\u001b[0m\n\u001b[1;32m     15\u001b[0m tqdm\u001b[38;5;241m.\u001b[39mpandas(desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranslating rows\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Translate each row with progress bar\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moriginal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogress_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerate_genz_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Save the modified DataFrame to a new CSV file\u001b[39;00m\n\u001b[1;32m     21\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(output_csv, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/main_venv/lib/python3.10/site-packages/tqdm/std.py:917\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;66;03m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[1;32m    915\u001b[0m \u001b[38;5;66;03m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_function\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    919\u001b[0m     t\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/main_venv/lib/python3.10/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/main_venv/lib/python3.10/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/main_venv/lib/python3.10/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/main_venv/lib/python3.10/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/main_venv/lib/python3.10/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/main_venv/lib/python3.10/site-packages/tqdm/std.py:912\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;66;03m# update tbar correctly\u001b[39;00m\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;66;03m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;66;03m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[1;32m    910\u001b[0m     \u001b[38;5;66;03m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[1;32m    911\u001b[0m     t\u001b[38;5;241m.\u001b[39mupdate(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mn \u001b[38;5;241m<\u001b[39m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 912\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 18\u001b[0m, in \u001b[0;36mreplace_generated_column.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     15\u001b[0m tqdm\u001b[38;5;241m.\u001b[39mpandas(desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranslating rows\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Translate each row with progress bar\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mprogress_apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mgenerate_genz_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Save the modified DataFrame to a new CSV file\u001b[39;00m\n\u001b[1;32m     21\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(output_csv, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[7], line 71\u001b[0m, in \u001b[0;36mgenerate_genz_text\u001b[0;34m(text, model, tokenizer, device, max_length)\u001b[0m\n\u001b[1;32m     62\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m tokenizer(\n\u001b[1;32m     63\u001b[0m     input_text,\n\u001b[1;32m     64\u001b[0m     max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     68\u001b[0m )\u001b[38;5;241m.\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# Generate output\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mno_repeat_ngram_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     77\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# Decode output\u001b[39;00m\n\u001b[1;32m     80\u001b[0m genz_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/main_venv/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/main_venv/lib/python3.10/site-packages/transformers/generation/utils.py:2286\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2278\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2279\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2280\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   2281\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2282\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2283\u001b[0m     )\n\u001b[1;32m   2285\u001b[0m     \u001b[38;5;66;03m# 13. run beam sample\u001b[39;00m\n\u001b[0;32m-> 2286\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_beam_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2287\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeam_scorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2292\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2293\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2294\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2296\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGROUP_BEAM_SEARCH:\n\u001b[1;32m   2297\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2298\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2299\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2300\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2306\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2307\u001b[0m     )\n",
      "File \u001b[0;32m~/main_venv/lib/python3.10/site-packages/transformers/generation/utils.py:3506\u001b[0m, in \u001b[0;36mGenerationMixin._beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   3503\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m stack_model_outputs(outputs_per_sub_batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget_text_config())\n\u001b[1;32m   3505\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Unchanged original behavior\u001b[39;00m\n\u001b[0;32m-> 3506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3508\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[1;32m   3509\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   3510\u001b[0m     outputs,\n\u001b[1;32m   3511\u001b[0m     model_kwargs,\n\u001b[1;32m   3512\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   3513\u001b[0m )\n",
      "File \u001b[0;32m~/main_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/main_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/main_venv/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1891\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1888\u001b[0m         decoder_attention_mask \u001b[38;5;241m=\u001b[39m decoder_attention_mask\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mfirst_device)\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;66;03m# Decode\u001b[39;00m\n\u001b[0;32m-> 1891\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1892\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1894\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1895\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1896\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1897\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1898\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1899\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1900\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1901\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1902\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1903\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1904\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1905\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1907\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m decoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1909\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m~/main_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/main_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/main_venv/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1124\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1107\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1108\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39mforward,\n\u001b[1;32m   1109\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1121\u001b[0m         cache_position,\n\u001b[1;32m   1122\u001b[0m     )\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1124\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1138\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;66;03m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[1;32m   1141\u001b[0m \u001b[38;5;66;03m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[1;32m   1142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m~/main_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/main_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/main_venv/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:699\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    697\u001b[0m do_cross_attention \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_decoder \u001b[38;5;129;01mand\u001b[39;00m encoder_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_cross_attention:\n\u001b[0;32m--> 699\u001b[0m     cross_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_value_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    710\u001b[0m     hidden_states, past_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;66;03m# clamp inf values to enable fp16 training\u001b[39;00m\n",
      "File \u001b[0;32m~/main_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/main_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/main_venv/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:629\u001b[0m, in \u001b[0;36mT5LayerCrossAttention.forward\u001b[0;34m(self, hidden_states, key_value_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, query_length, output_attentions, cache_position)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    617\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    626\u001b[0m     cache_position\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    627\u001b[0m ):\n\u001b[1;32m    628\u001b[0m     normed_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm(hidden_states)\n\u001b[0;32m--> 629\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEncDecAttention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormed_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_value_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_value_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    641\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attention_output[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    642\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m attention_output[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/main_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/main_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/main_venv/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:494\u001b[0m, in \u001b[0;36mT5Attention.forward\u001b[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions, cache_position)\u001b[0m\n\u001b[1;32m    491\u001b[0m is_updated \u001b[38;5;241m=\u001b[39m past_key_value\u001b[38;5;241m.\u001b[39mis_updated\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_idx)\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_cross_attention:\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;66;03m# after the first generated id, we can subsequently re-use all key/value_states from cache\u001b[39;00m\n\u001b[0;32m--> 494\u001b[0m     curr_past_key_value \u001b[38;5;241m=\u001b[39m \u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_attention_cache\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m     curr_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value\u001b[38;5;241m.\u001b[39mself_attention_cache\n",
      "File \u001b[0;32m~/main_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1918\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1909\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m   1911\u001b[0m \u001b[38;5;66;03m# On the return type:\u001b[39;00m\n\u001b[1;32m   1912\u001b[0m \u001b[38;5;66;03m# We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\u001b[39;00m\n\u001b[1;32m   1913\u001b[0m \u001b[38;5;66;03m# This is done for better interop with various type checkers for the end users.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[38;5;66;03m# See full discussion on the problems with returning `Union` here\u001b[39;00m\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;66;03m# https://github.com/microsoft/pyright/issues/4213\u001b[39;00m\n\u001b[0;32m-> 1918\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1919\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1920\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def replace_generated_column(input_csv, output_csv):\n",
    "    \"\"\"\n",
    "    Replace the 'generated' column in the input CSV with Gen Z style translations,\n",
    "    displaying a progress bar using tqdm.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    # Load the model and tokenizer\n",
    "    model, tokenizer = load_genz_model()\n",
    "\n",
    "    # Set up tqdm for pandas\n",
    "    tqdm.pandas(desc=\"Translating rows\")\n",
    "\n",
    "    # Translate each row with progress bar\n",
    "    df['generated'] = df['original'].progress_apply(lambda x: generate_genz_text(x, model, tokenizer, device))\n",
    "\n",
    "    # Save the modified DataFrame to a new CSV file\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Saved modified DataFrame to {output_csv}\")\n",
    "\n",
    "# Replace the generated column in the original CSV\n",
    "replace_generated_column('datasets/genz_emails_final.csv', 'datasets/genz_emails_final_translated.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2771facb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>generated</th>\n",
       "      <th>id</th>\n",
       "      <th>Hierarchy_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello ,\\n\\nI need a computer and flat screen m...</td>\n",
       "      <td>the location is EB3240E. ONLY- one computer an...</td>\n",
       "      <td>6868</td>\n",
       "      <td>Sender higher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Please disregard to prior version and use this...</td>\n",
       "      <td>slap the previous version and use this one, no...</td>\n",
       "      <td>24016</td>\n",
       "      <td>Sender higher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\t [IMAGE] \\t\\n\\tThanksgiving is just around...</td>\n",
       "      <td>[IMAGE] Thanksgiving is just around the corner...</td>\n",
       "      <td>9668</td>\n",
       "      <td>Recipient higher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The PRELIMINARY Violation Memos for 11/16/01 h...</td>\n",
       "      <td>the PRELIMINARY Violation Memos for 11/16/01 h...</td>\n",
       "      <td>13640</td>\n",
       "      <td>Recipient higher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Start Date: 3/30/01; HourAhead hour: 24;  No a...</td>\n",
       "      <td>no variances detected. LOG MESSAGES: PARSING F...</td>\n",
       "      <td>14018</td>\n",
       "      <td>Similar level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>west- san juan\\nplease change deal V96295 from...</td>\n",
       "      <td>change deal V96295 from gas daily to just a ny...</td>\n",
       "      <td>7488</td>\n",
       "      <td>Sender higher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I will be attending the Columbia Business Scho...</td>\n",
       "      <td>thanks for the invite. Ben Rogers</td>\n",
       "      <td>5804</td>\n",
       "      <td>Sender higher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\n\\tLinda, I went ahead and assigned Beverly M...</td>\n",
       "      <td>Linda, I went ahead and assigned Beverly Mille...</td>\n",
       "      <td>12909</td>\n",
       "      <td>Sender higher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A work order (J00136) has been set up on Gulf ...</td>\n",
       "      <td>a work order (J00136) has been set up on Gulf ...</td>\n",
       "      <td>3386</td>\n",
       "      <td>Recipient higher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Teams, Danny Collier, Region IX, EPA in Sanfra...</td>\n",
       "      <td>teams, Danny Collier, region IX, EPA in Sanfra...</td>\n",
       "      <td>9567</td>\n",
       "      <td>Sender higher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Panama Canal Cruise \\nShip: Sun Princess\\n1-90...</td>\n",
       "      <td>November 29, 2000 Delta Airlines DFW to Atlant...</td>\n",
       "      <td>21423</td>\n",
       "      <td>Recipient higher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Please be advised of the following:\\n\\n10/19 E...</td>\n",
       "      <td>10/19 ENOVATE DAILY LOSS $1.65 mlm10/19 eNOVAt...</td>\n",
       "      <td>3503</td>\n",
       "      <td>Recipient higher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Attached is the revised Committed Reserves Con...</td>\n",
       "      <td>attached is the revised Committed Reserves Con...</td>\n",
       "      <td>6657</td>\n",
       "      <td>Sender higher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Alert!  \\nYou are receiving this message becau...</td>\n",
       "      <td>your iPayit User ID and Password are your EHRo...</td>\n",
       "      <td>2647</td>\n",
       "      <td>Recipient higher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\\n-Larry Jester(mid yr-superior and yr end-str...</td>\n",
       "      <td>-Larry Jester(mid yr-superior and ir end-stron...</td>\n",
       "      <td>2518</td>\n",
       "      <td>Sender higher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Grant and Vince,\\n\\nThanks for arranging my vi...</td>\n",
       "      <td>i was super impressed by the vibe and scope of...</td>\n",
       "      <td>13361</td>\n",
       "      <td>Recipient higher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sara,\\n\\nI've asked Paul Garcia to get you a l...</td>\n",
       "      <td>Paul Garcia got you a legal contact name. he w...</td>\n",
       "      <td>21135</td>\n",
       "      <td>Recipient higher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Brett, for US applications dual fuel may be im...</td>\n",
       "      <td>Brett, for US applications dual fuel might be ...</td>\n",
       "      <td>21080</td>\n",
       "      <td>Sender higher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>These three guys will all be available for int...</td>\n",
       "      <td>these three guys will all be available for int...</td>\n",
       "      <td>6492</td>\n",
       "      <td>Recipient higher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Michael Gladwin has invited you to \"Vail 2002-...</td>\n",
       "      <td>http://evite.citysearch.com/r?iid=NHTERTPRBVJK...</td>\n",
       "      <td>6891</td>\n",
       "      <td>Recipient higher</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             original  \\\n",
       "0   Hello ,\\n\\nI need a computer and flat screen m...   \n",
       "1   Please disregard to prior version and use this...   \n",
       "2   \\n\\t [IMAGE] \\t\\n\\tThanksgiving is just around...   \n",
       "3   The PRELIMINARY Violation Memos for 11/16/01 h...   \n",
       "4   Start Date: 3/30/01; HourAhead hour: 24;  No a...   \n",
       "5   west- san juan\\nplease change deal V96295 from...   \n",
       "6   I will be attending the Columbia Business Scho...   \n",
       "7   \\n\\tLinda, I went ahead and assigned Beverly M...   \n",
       "8   A work order (J00136) has been set up on Gulf ...   \n",
       "9   Teams, Danny Collier, Region IX, EPA in Sanfra...   \n",
       "10  Panama Canal Cruise \\nShip: Sun Princess\\n1-90...   \n",
       "11  Please be advised of the following:\\n\\n10/19 E...   \n",
       "12  Attached is the revised Committed Reserves Con...   \n",
       "13  Alert!  \\nYou are receiving this message becau...   \n",
       "14  \\n-Larry Jester(mid yr-superior and yr end-str...   \n",
       "15  Grant and Vince,\\n\\nThanks for arranging my vi...   \n",
       "16  Sara,\\n\\nI've asked Paul Garcia to get you a l...   \n",
       "17  Brett, for US applications dual fuel may be im...   \n",
       "18  These three guys will all be available for int...   \n",
       "19  Michael Gladwin has invited you to \"Vail 2002-...   \n",
       "\n",
       "                                            generated     id   Hierarchy_Label  \n",
       "0   the location is EB3240E. ONLY- one computer an...   6868     Sender higher  \n",
       "1   slap the previous version and use this one, no...  24016     Sender higher  \n",
       "2   [IMAGE] Thanksgiving is just around the corner...   9668  Recipient higher  \n",
       "3   the PRELIMINARY Violation Memos for 11/16/01 h...  13640  Recipient higher  \n",
       "4   no variances detected. LOG MESSAGES: PARSING F...  14018     Similar level  \n",
       "5   change deal V96295 from gas daily to just a ny...   7488     Sender higher  \n",
       "6                   thanks for the invite. Ben Rogers   5804     Sender higher  \n",
       "7   Linda, I went ahead and assigned Beverly Mille...  12909     Sender higher  \n",
       "8   a work order (J00136) has been set up on Gulf ...   3386  Recipient higher  \n",
       "9   teams, Danny Collier, region IX, EPA in Sanfra...   9567     Sender higher  \n",
       "10  November 29, 2000 Delta Airlines DFW to Atlant...  21423  Recipient higher  \n",
       "11  10/19 ENOVATE DAILY LOSS $1.65 mlm10/19 eNOVAt...   3503  Recipient higher  \n",
       "12  attached is the revised Committed Reserves Con...   6657     Sender higher  \n",
       "13  your iPayit User ID and Password are your EHRo...   2647  Recipient higher  \n",
       "14  -Larry Jester(mid yr-superior and ir end-stron...   2518     Sender higher  \n",
       "15  i was super impressed by the vibe and scope of...  13361  Recipient higher  \n",
       "16  Paul Garcia got you a legal contact name. he w...  21135  Recipient higher  \n",
       "17  Brett, for US applications dual fuel might be ...  21080     Sender higher  \n",
       "18  these three guys will all be available for int...   6492  Recipient higher  \n",
       "19  http://evite.citysearch.com/r?iid=NHTERTPRBVJK...   6891  Recipient higher  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_df = pd.read_csv('datasets/genz_emails_final_translated.csv')\n",
    "\n",
    "\n",
    "trans_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03635ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID  : 19494\n",
      "Original  \n",
      " are you still partying tonight?  i think i am going to stay in, but i am \n",
      "definately up for going out tomorrow night.  \n",
      "\n",
      "\n",
      "Generated \n",
      " are you still ghosting tonight? i'm still sna party tonight, bruh? think u gonna stay in, but im definately up for going out tomorrow night.\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 4104\n",
      "Original  \n",
      " Hi, Vince,\n",
      "\n",
      "Please see attached the updated Total Return Swap deals. \n",
      "\n",
      "All the best!\n",
      "\n",
      "Li\n",
      "\n",
      "\n",
      "\n",
      "Generated \n",
      " yo, Vince, check attached the updated Total Return Swap deals. all the best! Li\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 18182\n",
      "Original  \n",
      " Please change the book coding on this log in to FT-Peoples.  Thanks.\n",
      "PL\n",
      "\n",
      "\n",
      "Generated \n",
      " please change the book coding on this log in to FT-Peoples. thanks. PL\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 5671\n",
      "Original  \n",
      " Per your request . . .\n",
      "\n",
      " - #1127382 v10 - NEW AGENCY AGREEMENT.doc\n",
      "\n",
      "\n",
      "Generated \n",
      " . -1127382 v10 - NEW AGENCY AGREEMENT.doc\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 9201\n",
      "Original  \n",
      " Hi Mary,\n",
      "\n",
      "Can you get someone to print this? the acrobat reader does not respond right.\n",
      "\n",
      "Thanks,\n",
      "\n",
      "C\n",
      "\n",
      "\n",
      "Generated \n",
      " hey Mary, can you get someone to print this? the acrobat reader doesn't respond right. thanks, C\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 2905\n",
      "Original  \n",
      " I did find one that I have not used.  You will just need to change the \n",
      "information at the top of the page.  \n",
      "\n",
      "\n",
      "\n",
      "Generated \n",
      " i found one that I haven't used yet. you'll just need to change the deets at the top of the page.\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 12064\n",
      "Original  \n",
      " Art Festival is week-end of Oct 14 and 15.  We're in.\n",
      "\n",
      "\n",
      "Generated \n",
      " art festival is week-end of Oct 14 and 15. we're in.\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 13991\n",
      "Original  \n",
      " We plan to send this out Friday.  Cynthia will provide copies to the Hill as \n",
      "she sees appropriate.  Any comments?\n",
      "\n",
      "\n",
      "Generated \n",
      " we're lowkey sending this out on Friday. Cynthia's gonna slide copies to the Hill as she sees appropriate. got any thoughts?\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 10727\n",
      "Original  \n",
      " missing deal for mark:\n",
      "\n",
      "sell williams\n",
      "129.50\n",
      "25 mw\n",
      "may\n",
      "paloverde\n",
      "off peak\n",
      "\n",
      "\n",
      "Generated \n",
      " mark: sell williams 129.50 25 mw may paloverde off peak\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 7405\n",
      "Original  \n",
      " BT,\n",
      "\n",
      "Attached is the SP proposal, please review by day's end if you can.\n",
      "\n",
      " \n",
      "\n",
      "dave\n",
      "\n",
      "\n",
      "Generated \n",
      " BT, attached is the SP proposal, pls review by day's end if you can. dave\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 4245\n",
      "Original  \n",
      " Oh great, he gets married, but his kids die from pollution.\n",
      "\n",
      "\n",
      "Generated \n",
      " hey great, he gets married, but his kids die from pollution.\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 397\n",
      "Original  \n",
      " \n",
      "\n",
      "\n",
      "\n",
      "                                  \n",
      "\n",
      "\n",
      "\n",
      "                                    Joe....\n",
      "\n",
      "\n",
      "Generated \n",
      " Joe....\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 16799\n",
      "Original  \n",
      " Vikki Gates\n",
      "Structure Consulting Group\n",
      "vikki.gates@scgo.com\n",
      "cell: 512.350.4020\n",
      "@ERCOT: 512.248.3884\n",
      "\n",
      "\n",
      " - 161_189.zip\n",
      "\n",
      "\n",
      "Generated \n",
      " vikki Gates Structure Consulting Group vikki.gates@scgo.com cell:512.350.4020 @ERCOT: 512.248.3884 - 161_189.zip\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 23655\n",
      "Original  \n",
      " I need to get copies of all the invoices for Dominion for ENA, VNG, and EES for Nov-01 through current please.\n",
      "\n",
      "\n",
      "\n",
      "thanks\n",
      "chris \n",
      "x3-4743\n",
      "Fax 713-646\n",
      "\n",
      "\n",
      "Generated \n",
      " thanks chris x3-4743 Fax 713-646\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 14717\n",
      "Original  \n",
      " Sasha has added \"DC-tie\" to the conterparty selection.  We can now do all deals ( Schedules ) across the tie if required through Eterra.\n",
      "\n",
      "\n",
      "Generated \n",
      " Sasha added \"DC-tie\" to the conterparty selection. we can now do all deals ( Schedules ) across the tie if required through Eterra.\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 22646\n",
      "Original  \n",
      " Since you are the father of this, I thought you'd want to see what we are up \n",
      "to.\n",
      "\n",
      "\n",
      "Linda Robertson\n",
      "202-466-9159\n",
      "\n",
      "\n",
      "\n",
      "   - DEMANDRE.WPD\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Generated \n",
      " Linda Robertson 202-466-9159 - DEMANDRE.WPD\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 11006\n",
      "Original  \n",
      " You betcha,  I get off around 5:30-5:45 where were you thinking.\n",
      "\n",
      "\n",
      "Generated \n",
      " you betcha, i get off around 5:30-5:45 where were you thinking.\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 18570\n",
      "Original  \n",
      " rite spot.  17th and folsom.  the best.\n",
      "\n",
      "Best,\n",
      "Jeff\n",
      "\n",
      "\n",
      "Generated \n",
      " 17th and folsom. the best. best, Jeff\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 7889\n",
      "Original  \n",
      " Teco Tap       10.000 / Enron ; 80.000 / HPL IFERC\n",
      "\n",
      "LS HPL LSK IC       30.000 / Enron\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Generated \n",
      " Teco Tap 10.000 / Enron ; 80.000 HPL IFERC LS PSL LSK IC 30.000\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 20268\n",
      "Original  \n",
      " bherod@enron.com and mmoscoso@enron.com.  Mike's may be incorrect, let me \n",
      "know if it fails.\n",
      "PL\n",
      "\n",
      "\n",
      "Generated \n",
      " Mike's might be lowkey incorrect, hit me up if it fails. PL\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 10280\n",
      "Original  \n",
      " See attached for liquids gathered for this months sample run. Results will \n",
      "follow.                                            \n",
      "\n",
      "\n",
      "Generated \n",
      " see attached for liquids gathered for this month sample run. results will follow.\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 18582\n",
      "Original  \n",
      " Also:  Steve/Maureen:\n",
      "\n",
      "Please see draft letters which we plan to forward to Rosie/Tori today for Ken \n",
      "Lay's approval:\n",
      "\n",
      "\n",
      "\n",
      "Generated \n",
      " lowkey: Steve/Maureen: please peep draft letters we're gonna slide to Rosie/Tori today for Ken Lay's approval:\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 1122\n",
      "Original  \n",
      " I added a couple of our other businesses in the opening paragragh.\n",
      "\n",
      "Good to go.\n",
      "\n",
      "mike\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Generated \n",
      " i added a couple of our other businesses in the opening paragragh. good to go. mike\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 5804\n",
      "Original  \n",
      " I will be attending the Columbia Business School session this Monday in \n",
      "Houston.  Thank you for the invitation.\n",
      "Ben Rogers\n",
      "\n",
      "\n",
      "Generated \n",
      " thanks for the invite. Ben Rogers\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 4966\n",
      "Original  \n",
      " Suz,\n",
      "\n",
      "Please print two originals of this CA (in my CA directory) InterGen North \n",
      "America CA May 18 rev 1.\n",
      "\n",
      "Thanks,\n",
      "\n",
      "Kay\n",
      "\n",
      "\n",
      "Generated \n",
      " please print two originals of this CA (in my CA directory) InterGen North America CA May 18 rev 1. thanks, Kay\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 21123\n",
      "Original  \n",
      " Attached is an ENA form of confirmation for a Gas Daily swap (documented \n",
      "under an executed ISDA Master Agreement).  Sara\n",
      "\n",
      "\n",
      "\n",
      "Generated \n",
      " attached is an ENA form of confirmation for a gas Daily swap (documented under an executed ISDA Master Agreement). Sara\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 18824\n",
      "Original  \n",
      " Please click the link below to complete the QuickBase registration process.\n",
      "\n",
      "https://www.quickbase.com/db/main?a=DoEnableReg&k=f3dv&m=rpxrf\n",
      "\n",
      "\n",
      "Generated \n",
      " please click the link below to complete the QuickBase registration process. https://www.quickbase.com/db/main?a=DoEnableReg&k=f3dv&m=rpxrf\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 23919\n",
      "Original  \n",
      " The attached letter is being sent to you from Patricia Gillman.\n",
      "\n",
      "(See attached file: Sanders Letter 4_28_00.doc)\n",
      "\n",
      " - Sanders Letter 4_28_00.doc\n",
      "\n",
      "\n",
      "Generated \n",
      " - Sanders Letter 4_28_00.doc\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 15811\n",
      "Original  \n",
      " Tickets were still available so I'm going.  Commitment.\n",
      "\n",
      "\n",
      "Generated \n",
      " i got the tickets still available so I'm going. commitment.\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 14170\n",
      "Original  \n",
      " Robert Bradley asked me to forward this presentation to you.\n",
      "\n",
      "\n",
      "Thanks \n",
      "Katrina B.\n",
      "\n",
      "\n",
      "Generated \n",
      " ty Katrina B.\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 16922\n",
      "Original  \n",
      " Cool.  I actually left a message with Ted, but obviously I've heard nothing.\n",
      "\n",
      "\n",
      "Generated \n",
      " lowkey cool. i actually left a message with Ted, but obviously I've heard nothing.\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 24671\n",
      "Original  \n",
      " Everyone in RAC is invited to attend Underwriting mtg on Friday at 10:30 am. \n",
      "Rick\n",
      "\n",
      "\n",
      "Generated \n",
      " everyone in RAC is invited to vibe at Underwriting mtg on Friday at 10:30 am. Rick\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 19137\n",
      "Original  \n",
      " Hi Gerald:  Surprisingly enough, we have no executed agreements with or \n",
      "pertaining to either Florida or Koch, to the best of my knowledge.\n",
      "\n",
      "Kay\n",
      "\n",
      "\n",
      "Generated \n",
      " Hi Gerald: Surprisingly enough, we have no executed agreements with or pertaining to either Florida or Koch, to my knowledge. Kay\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 5117\n",
      "Original  \n",
      " Happy Thanksgiving to you all and your families!\n",
      "God Bless each of you!\n",
      "Vicki Rose\n",
      "\n",
      "\n",
      "Generated \n",
      " cheer Thanksgiving to you all and your families! God Bless each of you! Vicki Rose\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 4418\n",
      "Original  \n",
      " \n",
      "turn up the volume\n",
      "\n",
      "http://www.major3d.com/animate/Mouse_final.mpeg\n",
      "\n",
      "\n",
      "Generated \n",
      " turn up the volume http://www.major3d.com/animate/Mouse_final.mpeg\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 6136\n",
      "Original  \n",
      " Hey, check out the Florida surf yesterday. Pretty sweet, eh? (for florida at \n",
      "least)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Generated \n",
      " pretty sweet, eh? (for florida at least)\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 14417\n",
      "Original  \n",
      " Please find attached the final draft of the Sydney/Singapore presentations \n",
      "for you review and distribution.  Thank you.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Generated \n",
      " please find attached the final draft of the Sydney/Singapore presentations for you review and distribution. thanks.\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 20945\n",
      "Original  \n",
      " Hi:\n",
      "you taking the afternoon off?  If so, have a great afternoon!\n",
      "\n",
      "Best,\n",
      "Jeff\n",
      "\n",
      "\n",
      "Generated \n",
      " Hi: you taking the afternoon off? if so, have a great afternoon! Best, Jeff\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 10159\n",
      "Original  \n",
      " Thanks - my question about the increments was directed to LADWP.  Are they giving us a 10 Min call ? \n",
      "\n",
      "NFB \n",
      "\n",
      "\n",
      "Generated \n",
      " thanks - my question about the increment increments was directed to LADWP. are they giving us a 10 min call? NFB\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 8170\n",
      "Original  \n",
      " Attached is the monthly report.  Please send me any additions or changes you \n",
      "might have as soon as possible.\n",
      "\n",
      "  Thanks.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Generated \n",
      " attached is the monthly report. hit me with any adds or changes you might have asap. thanks.\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 819\n",
      "Original  \n",
      " What is the issue?  I have no idea if anyone is looking at this.  Sara\n",
      "\n",
      "\n",
      "Generated \n",
      " what' what is the issue? i have no idea if anyone is looking at this. Sara\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 9161\n",
      "Original  \n",
      " Please see the attached voicemail that Steve received today from Woody \n",
      "Wodraska.\n",
      "\n",
      "\n",
      "\n",
      "Generated \n",
      " please check the attached voicemail that Steve got today from Woody Wodraska.\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 17548\n",
      "Original  \n",
      " Please respond to Larry Taylor's new e-mail address is:\n",
      "\n",
      "\tTaylor@BeAnOrange.com\n",
      "\n",
      "\n",
      "Generated \n",
      " hit Larry Taylor's new email address: Taylor@BeAnOrange.com\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 17093\n",
      "Original  \n",
      " I'm thinking about seeing them tomorrow - lettin' em chill.\n",
      "\n",
      "I'm going to try to make the Thursday 4:00PM appointment.\n",
      "\n",
      "\n",
      "Generated \n",
      " yo seeing them tomorrow - lettin' em chill. i'm gonna try to make the Thursday 4:00PM appointment.\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 17112\n",
      "Original  \n",
      " Tana:\n",
      "\n",
      "Commonwealth Gas Company is NOT approved to trade US power -- not a current \n",
      "trading partner and not FERC authorized.\n",
      "\n",
      "Leslie\n",
      "\n",
      "\n",
      "Generated \n",
      " Tana: the Commonwealth Gas Company is NOT approved to trade US power -- not a current trading partner and no FERC authorized. Leslie\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 748\n",
      "Original  \n",
      " Jane:\n",
      "Refer to question #2 for the Gleason answer.  Please let me know if you have \n",
      "any other questions.\n",
      "Ben\n",
      "\n",
      "\n",
      "\n",
      "Generated \n",
      " Jane: refer to question #2 for the Gleason answer. hit me up if you have any other questions. Ben\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 1429\n",
      "Original  \n",
      " Maria:\n",
      "Wanted to let you know that I just faxed over a two page document.  Thanks\n",
      "Ben Rogers\n",
      "\n",
      "\n",
      "Generated \n",
      " lowkey wanted to let you know that i just faxed over a two page doc. thanks Ben Rogers\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 15999\n",
      "Original  \n",
      " FYI. See attached. Any questions, please call me at ext. 39932. Thanks.\n",
      "\n",
      "Kimat\n",
      "\n",
      "\n",
      "Generated \n",
      " if you got any questions, hit me up at ext. 39932. thanks. Kimat\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 14337\n",
      "Original  \n",
      " Please see the attached memo and blacklined Master Firm Gas Purchase/Sale \n",
      "Agreement.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Generated \n",
      " check the attached memo and the blacklined Master Firm Gas Purchase/Sale agreement.\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "ID  : 315\n",
      "Original  \n",
      " hey sheri -- i forgot my logon and password for dynegy direct -- we havent \n",
      "looked at it in so long but now we want to again.\n",
      "\n",
      "\n",
      "Generated \n",
      " hey sheri -- i forgot my logon and password for dynegy direct -- we havent looked at it for so long but now we wanna again.\n",
      "\n",
      "\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# print the first 50 rows of original and generated columns whose length is less than 50\n",
    "\n",
    "\n",
    "# Filter rows with 'original' length < 50\n",
    "filtered_df = trans_df[trans_df['original'].str.len() > 50]\n",
    "filtered_df = filtered_df[filtered_df['original'].str.len() < 150]\n",
    "\n",
    "# Sample up to 50 such rows\n",
    "sampled_df = filtered_df.sample(n=min(50, len(filtered_df)), random_state=42)\n",
    "\n",
    "# Print each sample neatly\n",
    "for i, row in sampled_df.iterrows():\n",
    "    print(f\"ID  : {row['id']}\")\n",
    "    print(f\"Original  \\n {row['original']}\\n\\n\")\n",
    "    print(f\"Generated \\n {row['generated']}\\n\\n\")\n",
    "    print('-' * 40)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
