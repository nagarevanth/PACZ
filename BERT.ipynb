{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import spacy\n",
    "\n",
    "sample_dataset = \"../datasets/sample_emails.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 1. Text Preprocessing Utilities\n",
    "# -----------------------------\n",
    "\n",
    "# def tokenize(text):\n",
    "\n",
    "#     if not isinstance(text, str):\n",
    "#         text = str(text)\n",
    "\n",
    "#     word_pattern = r\"\"\"\n",
    "#         \\b(?:Mr|Mrs|Ms|Dr|Prof|Sr|Jr|St)\\.    # Common abbreviations with a period\n",
    "#         | \\b\\w+://[^\\s]+                      # URLs\n",
    "#         | [A-Za-z]+(?:'t|'ve|'d|'re|'ll|'m|n't)?  # Contractions\n",
    "#         | \\d+(?:\\.\\d+)?(?:[a-z]+)?            # Numbers and percentages\n",
    "#         | [\\w\\-]+                             # Words with hyphens\n",
    "#         | [^\\w\\s]+                            # Punctuation\n",
    "#         \"\"\"\n",
    "#     tokenized_words =  re.findall(word_pattern, text, re.VERBOSE)\n",
    "\n",
    "#     return tokenized_words\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"Converts input to string, lowercases, and splits by whitespace.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    return text.lower().split()\n",
    "\n",
    "def build_vocab(sentences, min_freq=1):\n",
    "    \"\"\"Build a vocabulary mapping from token to index.\"\"\"\n",
    "    counter = Counter()\n",
    "    for sent in sentences:\n",
    "        counter.update(tokenize(sent))\n",
    "    # Reserve index 0 for padding and 1 for unknown tokens\n",
    "    vocab = {word: i + 2 for i, (word, count) in enumerate(counter.items()) if count >= min_freq}\n",
    "    vocab['<PAD>'] = 0\n",
    "    vocab['<UNK>'] = 1\n",
    "    return vocab\n",
    "\n",
    "def text_to_indices(text, vocab):\n",
    "    \"\"\"Convert text string to a list of token indices.\"\"\"\n",
    "    tokens = tokenize(text)\n",
    "    return [vocab.get(token, vocab['<UNK>']) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 2. Dataset Definition\n",
    "# -----------------------------\n",
    "\n",
    "class EmailHierarchyDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for emails with hierarchy labels.\n",
    "    Assumes the CSV file has:\n",
    "      - 'content': preprocessed email text (input)\n",
    "      - 'hierarchy_label': the hierarchy label (output)\n",
    "    \"\"\"\n",
    "    def __init__(self, csv_file=None, df=None, vocab=None, max_len=100):\n",
    "        if csv_file is not None:\n",
    "            self.data = pd.read_csv(csv_file)\n",
    "        elif df is not None:\n",
    "            self.data = df\n",
    "        else:\n",
    "            raise ValueError(\"Either csv_file or df must be provided\")\n",
    "            \n",
    "        # Map the hierarchy_label to an integer index\n",
    "        self.label_mapping = {\n",
    "                'Sender higher': 0,\n",
    "                'Similar level': 1,\n",
    "                'Recipient higher': 2,\n",
    "                # 'Unknown': 3\n",
    "            }\n",
    "        self.data['label'] = self.data['Hierarchy_Label'].map(self.label_mapping)\n",
    "        \n",
    "        # Inverse mapping for result interpretation\n",
    "        self.idx_to_label = {idx: label for label, idx in self.label_mapping.items()}\n",
    "\n",
    "        # Build vocabulary if not provided\n",
    "        if vocab is None:\n",
    "            self.vocab = build_vocab(self.data['content'].tolist())\n",
    "        else:\n",
    "            self.vocab = vocab\n",
    "\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        text = row['content']\n",
    "        label = row['label']\n",
    "        indices = text_to_indices(text, self.vocab)\n",
    "        # Pad or truncate the sequence to max_len\n",
    "        if len(indices) < self.max_len:\n",
    "            indices = indices + [self.vocab['<PAD>']] * (self.max_len - len(indices))\n",
    "        else:\n",
    "            indices = indices[:self.max_len]\n",
    "        return torch.tensor(indices, dtype=torch.long), torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Total dataset size: 25000\n",
      "Training set size: 20000\n",
      "Test set size: 5000\n",
      "Vocabulary size: 83649\n",
      "Number of classes: 3\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "\n",
    "# Hyper parameters\n",
    "embedding_dim = 256\n",
    "hidden_dim = 256\n",
    "num_layers = 2\n",
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "learning_rate = 0.0002\n",
    "max_len = 200\n",
    "test_size = 0.2\n",
    "\n",
    "# Load the dataset (ensure the CSV file is in your working directory)\n",
    "full_dataset = EmailHierarchyDataset(sample_dataset, max_len=max_len)\n",
    "\n",
    "# Split dataset into train and test sets\n",
    "train_size = int((1 - test_size) * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Determine vocabulary size and number of classes from the dataset\n",
    "vocab_size = len(full_dataset.vocab)\n",
    "output_dim = len(full_dataset.label_mapping)\n",
    "\n",
    "# Print dataset statistics\n",
    "print(f\"Total dataset size: {len(full_dataset)}\")\n",
    "print(f\"Training set size: {len(train_dataset)}\")\n",
    "print(f\"Test set size: {len(test_dataset)}\")\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "print(f\"Number of classes: {output_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5460908f21324a53993108fee4e97e94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def anonymize_names(text):\n",
    "    doc = nlp(text)\n",
    "    replaced = text\n",
    "    for ent in reversed(doc.ents):  # Reversed to avoid index shifting\n",
    "        if ent.label_ == \"PERSON\":\n",
    "            replaced = replaced[:ent.start_char] + \"<NAME>\" + replaced[ent.end_char:]\n",
    "    return replaced\n",
    "\n",
    "df = full_dataset.data\n",
    "\n",
    "# make a dataset which contains only content and label\n",
    "\n",
    "df = df[['content', 'label']]\n",
    "df.loc[:, 'content'] = df['content'].astype(str)\n",
    "df.loc[:, 'content'] = df['content'].apply(anonymize_names)\n",
    "df.loc[:, 'label'] = df['label'].astype(int)\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "print('here')\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def tokenize(exmaple):\n",
    "    return tokenizer(exmaple[\"content\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, batched = True)\n",
    "tokenized_dataset = tokenized_dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    max_grad_norm=1.0,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir='./logs',\n",
    "    fp16=False,\n",
    "    no_cuda=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    ")\n",
    "trainer.train()\n",
    "trainer.evaluate()\n",
    "# Save the model\n",
    "model.save_pretrained(\"./email_hierarchy_model\")\n",
    "tokenizer.save_pretrained(\"./email_hierarchy_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            original   \n",
      "0  Hello ,\\n\\nI need a computer and flat screen m...  \\\n",
      "1  Please disregard to prior version and use this...   \n",
      "2  \\n\\t [IMAGE] \\t\\n\\tThanksgiving is just around...   \n",
      "3  The PRELIMINARY Violation Memos for 11/16/01 h...   \n",
      "4  Start Date: 3/30/01; HourAhead hour: 24;  No a...   \n",
      "\n",
      "                                           generated     id   Hierarchy_Label  \n",
      "0  the location is EB3240E. ONLY- one computer an...   6868     Sender higher  \n",
      "1  slap the previous version and use this one, no...  24016     Sender higher  \n",
      "2  [IMAGE] Thanksgiving is just around the corner...   9668  Recipient higher  \n",
      "3  the PRELIMINARY Violation Memos for 11/16/01 h...  13640  Recipient higher  \n",
      "4  no variances detected. LOG MESSAGES: PARSING F...  14018     Similar level  \n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load model and tokenizer from saved directory\n",
    "model_path = \"../email_hierarchy_model\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# Set model to evaluation mode and move to device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "idx_to_label = {\n",
    "    0: \"Sender higher\",\n",
    "    1: \"Similar level\",\n",
    "    2: \"Recipient higher\"\n",
    "}\n",
    "\n",
    "def predict_label(text):\n",
    "    # Tokenize input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=128)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    # Run the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        probabilities = F.softmax(logits, dim=1)\n",
    "        predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "        confidence = probabilities[0][predicted_class].item()\n",
    "\n",
    "    return idx_to_label[predicted_class], confidence\n",
    "\n",
    "# Test the model with test data\n",
    "test_data_path = \"../datasets/genz_emails_final_translated.csv\"\n",
    "test_df = pd.read_csv(test_data_path)\n",
    "\n",
    "print(test_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2503/2503 [01:07<00:00, 36.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.21%\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Recipient higher     0.9328    0.9121    0.9224      1081\n",
      "   Sender higher     0.9272    0.9464    0.9367      1306\n",
      "   Similar level     0.9823    0.9569    0.9694       116\n",
      "\n",
      "        accuracy                         0.9321      2503\n",
      "       macro avg     0.9475    0.9385    0.9428      2503\n",
      "    weighted avg     0.9322    0.9321    0.9320      2503\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 986   93    2]\n",
      " [  70 1236    0]\n",
      " [   1    4  111]]\n",
      "Confusion matrix saved as 'confusion_matrix.png'\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "test_df = test_df[['original', 'Hierarchy_Label']]\n",
    "test_df.loc[:, 'original'] = test_df['original'].astype(str)\n",
    "test_df.loc[:, 'Hierarchy_Label'] = test_df['Hierarchy_Label'].astype(str)\n",
    "\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "confidences = []\n",
    "texts = []\n",
    "\n",
    "for index, row in tqdm(test_df.iterrows(), total=test_df.shape[0]):\n",
    "    text = row['original']\n",
    "    true_label = row['Hierarchy_Label']\n",
    "    predicted_label, confidence = predict_label(text)\n",
    "\n",
    "    texts.append(text)\n",
    "    true_labels.append(true_label)\n",
    "    predicted_labels.append(predicted_label)\n",
    "    confidences.append(confidence)\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_labels, predicted_labels, digits=4))\n",
    "\n",
    "# Optional: Confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Store results if needed\n",
    "results_df = pd.DataFrame({\n",
    "    'Text': texts,\n",
    "    'True_Label': true_labels,\n",
    "    'Predicted_Label': predicted_labels,\n",
    "    'Confidence': confidences\n",
    "})\n",
    "\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png')\n",
    "print(\"Confusion matrix saved as 'confusion_matrix.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2503 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2503/2503 [03:03<00:00, 13.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.30%\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Recipient higher     0.8571    0.7993    0.8272      1081\n",
      "   Sender higher     0.8401    0.8974    0.8678      1306\n",
      "   Similar level     0.9900    0.8534    0.9167       116\n",
      "\n",
      "        accuracy                         0.8530      2503\n",
      "       macro avg     0.8958    0.8500    0.8706      2503\n",
      "    weighted avg     0.8544    0.8530    0.8525      2503\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 864  216    1]\n",
      " [ 134 1172    0]\n",
      " [  10    7   99]]\n",
      "Confusion matrix saved as 'confusion_matrix.png'\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6MAAAMWCAYAAAAEYVDaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABS+klEQVR4nO3de9zX8/0/8Mfnoq6SzulkOmDIYUKWHHJKOY0cvmaMmM1sZQjD5phDY4455SzGZpthDkPKYUiInDVnGzpJpVCp6/eHn2ufa4Xi6n1V7vfb7XO77Xq935/35/n53Gp5Xo/n5/UuVVVVVQUAAAAKVFHXBQAAAPDtoxkFAACgcJpRAAAACqcZBQAAoHCaUQAAAAqnGQUAAKBwmlEAAAAKpxkFAACgcJpRAAAACqcZBSBJ8sorr6R3795p2rRpSqVSbr311lq9/ptvvplSqZRrr722Vq+7NNtqq62y1VZb1XUZAFAnNKMAS5DXXnstP//5z7PqqqumQYMGadKkSTbbbLNccMEF+fjjjxfra/fr1y/PPfdcTj/99Fx//fXp1q3bYn29Ih1wwAEplUpp0qTJAj/HV155JaVSKaVSKWefffYiX//dd9/NySefnLFjx9ZCtQDw7bB8XRcAwGfuvPPO/N///V8qKyuz//77Z911183s2bPz8MMP5+ijj84LL7yQyy+/fLG89scff5xRo0blt7/9bQYMGLBYXqNjx475+OOPU69evcVy/a+y/PLL56OPPsrtt9+evfbaq8axG264IQ0aNMgnn3zyta797rvv5pRTTkmnTp3StWvXhX7evffe+7VeDwCWBZpRgCXAG2+8kb333jsdO3bMyJEj065du+pj/fv3z6uvvpo777xzsb3+pEmTkiTNmjVbbK9RKpXSoEGDxXb9r1JZWZnNNtssf/zjH+drRm+88cbstNNOufnmmwup5aOPPsoKK6yQ+vXrF/J6ALAkMqYLsAQ466yzMmPGjFx11VU1GtHPrb766jnssMOqf/70009z6qmnZrXVVktlZWU6deqU3/zmN5k1a1aN53Xq1Ck777xzHn744Xz/+99PgwYNsuqqq+a6666rPufkk09Ox44dkyRHH310SqVSOnXqlOSz8dbP/3e5k08+OaVSqcba8OHDs/nmm6dZs2ZZccUVs+aaa+Y3v/lN9fEv+s7oyJEjs8UWW6RRo0Zp1qxZdt1117z00ksLfL1XX301BxxwQJo1a5amTZvmwAMPzEcfffTFH+z/2GefffKPf/wjU6dOrV574okn8sorr2SfffaZ7/wpU6bkqKOOynrrrZcVV1wxTZo0yQ477JBnnnmm+pwHHnggG2+8cZLkwAMPrB73/fx9brXVVll33XUzZsyY9OzZMyussEL15/K/3xnt169fGjRoMN/779OnT5o3b5533313od8rACzpNKMAS4Dbb789q666ajbddNOFOv+nP/1pTjzxxGy44YY577zzsuWWW2bw4MHZe++95zv31VdfzZ577pntttsu55xzTpo3b54DDjggL7zwQpJk9913z3nnnZck+dGPfpTrr78+559//iLV/8ILL2TnnXfOrFmzMmjQoJxzzjnZZZdd8sgjj3zp8+6777706dMnEydOzMknn5yBAwfm0UcfzWabbZY333xzvvP32muvfPjhhxk8eHD22muvXHvttTnllFMWus7dd989pVIpf/vb36rXbrzxxqy11lrZcMMN5zv/9ddfz6233pqdd9455557bo4++ug899xz2XLLLasbwy5dumTQoEFJkoMPPjjXX399rr/++vTs2bP6Ou+//3522GGHdO3aNeeff3623nrrBdZ3wQUXZKWVVkq/fv0yd+7cJMlll12We++9NxdeeGHat2+/0O8VAJZ4VQDUqWnTplUlqdp1110X6vyxY8dWJan66U9/WmP9qKOOqkpSNXLkyOq1jh07ViWpeuihh6rXJk6cWFVZWVl15JFHVq+98cYbVUmqfv/739e4Zr9+/ao6duw4Xw0nnXRSVfk/Ieedd15VkqpJkyZ9Yd2fv8Y111xTvda1a9eq1q1bV73//vvVa88880xVRUVF1f777z/f6/3kJz+pcc3ddtutqmXLll/4muXvo1GjRlVVVVVVe+65Z9W2225bVVVVVTV37tyqtm3bVp1yyikL/Aw++eSTqrlz5873PiorK6sGDRpUvfbEE0/M994+t+WWW1YlqRo6dOgCj2255ZY11u65556qJFWnnXZa1euvv1614oorVvXt2/cr3yMALG0kowB1bPr06UmSxo0bL9T5d911V5Jk4MCBNdaPPPLIJJnvu6Vrr712tthii+qfV1pppay55pp5/fXXv3bN/+vz75redtttmTdv3kI957333svYsWNzwAEHpEWLFtXr3/ve97LddttVv89yhxxySI2ft9hii7z//vvVn+HC2GefffLAAw9k/PjxGTlyZMaPH7/AEd3ks++ZVlR89k/l3Llz8/7771ePID/11FML/ZqVlZU58MADF+rc3r175+c//3kGDRqU3XffPQ0aNMhll1220K8FAEsLzShAHWvSpEmS5MMPP1yo8996661UVFRk9dVXr7Hetm3bNGvWLG+99VaN9Q4dOsx3jebNm+eDDz74mhXP74c//GE222yz/PSnP02bNm2y9957589//vOXNqaf17nmmmvOd6xLly6ZPHlyZs6cWWP9f99L8+bNk2SR3suOO+6Yxo0b56abbsoNN9yQjTfeeL7P8nPz5s3Leeedl+9+97uprKxMq1atstJKK+XZZ5/NtGnTFvo1V1555UXarOjss89OixYtMnbs2AwZMiStW7de6OcCwNJCMwpQx5o0aZL27dvn+eefX6Tn/e8GQl9kueWWW+B6VVXV136Nz7/P+LmGDRvmoYceyn333Zf99tsvzz77bH74wx9mu+22m+/cb+KbvJfPVVZWZvfdd8+wYcNyyy23fGEqmiRnnHFGBg4cmJ49e+YPf/hD7rnnngwfPjzrrLPOQifAyWefz6J4+umnM3HixCTJc889t0jPBYClhWYUYAmw884757XXXsuoUaO+8tyOHTtm3rx5eeWVV2qsT5gwIVOnTq3eGbc2NG/evMbOs5/73/Q1SSoqKrLtttvm3HPPzYsvvpjTTz89I0eOzP3337/Aa39e57hx4+Y79vLLL6dVq1Zp1KjRN3sDX2CfffbJ008/nQ8//HCBmz597q9//Wu23nrrXHXVVdl7773Tu3fv9OrVa77PZGF/MbAwZs6cmQMPPDBrr712Dj744Jx11ll54oknau36ALCk0IwCLAF+/etfp1GjRvnpT3+aCRMmzHf8tddeywUXXJDkszHTJPPteHvuuecmSXbaaadaq2u11VbLtGnT8uyzz1avvffee7nllltqnDdlypT5ntu1a9ckme92M59r165dunbtmmHDhtVo7p5//vnce++91e9zcdh6661z6qmn5qKLLkrbtm2/8LzllltuvtT1L3/5S955550aa583zQtq3BfVMccck7fffjvDhg3Lueeem06dOqVfv35f+DkCwNJq+bouAIDPmr4bb7wxP/zhD9OlS5fsv//+WXfddTN79uw8+uij+ctf/pIDDjggSbL++uunX79+ufzyyzN16tRsueWWefzxxzNs2LD07dv3C28b8nXsvffeOeaYY7LbbrvlV7/6VT766KNceumlWWONNWps4DNo0KA89NBD2WmnndKxY8dMnDgxl1xySb7zne9k8803/8Lr//73v88OO+yQHj165KCDDsrHH3+cCy+8ME2bNs3JJ59ca+/jf1VUVOT444//yvN23nnnDBo0KAceeGA23XTTPPfcc7nhhhuy6qqr1jhvtdVWS7NmzTJ06NA0btw4jRo1Svfu3dO5c+dFqmvkyJG55JJLctJJJ1Xfauaaa67JVlttlRNOOCFnnXXWIl0PAJZkklGAJcQuu+ySZ599NnvuuWduu+229O/fP8cee2zefPPNnHPOORkyZEj1uVdeeWVOOeWUPPHEEzn88MMzcuTIHHfccfnTn/5UqzW1bNkyt9xyS1ZYYYX8+te/zrBhwzJ48OD84Ac/mK/2Dh065Oqrr07//v1z8cUXp2fPnhk5cmSaNm36hdfv1atX7r777rRs2TInnnhizj777GyyySZ55JFHFrmRWxx+85vf5Mgjj8w999yTww47LE899VTuvPPOrLLKKjXOq1evXoYNG5blllsuhxxySH70ox/lwQcfXKTX+vDDD/OTn/wkG2ywQX77299Wr2+xxRY57LDDcs455+Sxxx6rlfcFAEuCUtWi7PoAAAAAtUAyCgAAQOE0owAAABROMwoAAEDhNKMAAAAUTjMKAABA4TSjAAAAFE4zCgAAQOGWr+sCFofvHn13XZcALAa3HLZ5XZcALCart12xrksAFoMGS2m30XCDAXVdQrWPn76orktYbCSjAAAAFE4zCgAAQOGW0uAcAABgMSnJ7IrgUwYAAKBwmlEAAAAKZ0wXAACgXKlU1xV8K0hGAQAAKJxmFAAAgMIZ0wUAAChnN91C+JQBAAAonGQUAACgnA2MCiEZBQAAoHCaUQAAAApnTBcAAKCcDYwK4VMGAACgcJpRAAAACmdMFwAAoJzddAshGQUAAKBwmlEAAAAKZ0wXAACgnN10C+FTBgAAoHCSUQAAgHI2MCqEZBQAAIDCaUYBAAAonDFdAACAcjYwKoRPGQAAgMJpRgEAACicMV0AAIBydtMthGQUAACAwmlGAQAAKJwxXQAAgHJ20y2ETxkAAIDCSUYBAADK2cCoEJJRAAAACqcZBQAAoHDGdAEAAMrZwKgQPmUAAAAKpxkFAACgcMZ0AQAAyhnTLYRPGQAAgMJpRgEAACicMV0AAIByFaW6ruBbQTIKAABA4SSjAAAA5WxgVAifMgAAAIXTjAIAAFA4Y7oAAADlSjYwKoJkFAAAgMJpRgEAACicMV0AAIBydtMthE8ZAACAwmlGAQAAKJwxXQAAgHJ20y2EZBQAAIDCSUYBAADK2cCoED5lAAAACqcZBQAAoHDGdAEAAMrZwKgQklEAAAAKpxkFAACgcMZ0AQAAytlNtxA+ZQAAAAqnGQUAAKBwxnQBAADK2U23EJJRAAAACicZBQAAKGcDo0L4lAEAACicZhQAAIDCGdMFAAAoZwOjQkhGAQAAKJxmFAAAgMIZ0wUAAChnN91C+JQBAAAonGYUAACAwhnTBQAAKGdMtxA+ZQAAAAonGQUAACjnPqOFkIwCAABQOM0oAAAAhTOmCwAAUM4GRoXwKQMAAFA4zSgAAACFM6YLAABQzm66hZCMAgAAUDjNKAAAAIUzpgsAAFDObrqF8CkDAABQOMkoAABAORsYFUIyCgAAQOE0owAAABTOmC4AAECZkjHdQkhGAQAAKJxmFAAAgMIZ0wUAAChjTLcYklEAAAAKpxkFAACgcMZ0AQAAypnSLYRkFAAAgMJpRgEAAMqUSqUl5rEoHnroofzgBz9I+/btUyqVcuutt9Y4XlVVlRNPPDHt2rVLw4YN06tXr7zyyis1zpkyZUr23XffNGnSJM2aNctBBx2UGTNm1Djn2WefzRZbbJEGDRpklVVWyVlnnfW1PmfNKAAAwDJg5syZWX/99XPxxRcv8PhZZ52VIUOGZOjQoRk9enQaNWqUPn365JNPPqk+Z999980LL7yQ4cOH54477shDDz2Ugw8+uPr49OnT07t373Ts2DFjxozJ73//+5x88sm5/PLLF7le3xkFAABYBuywww7ZYYcdFnisqqoq559/fo4//vjsuuuuSZLrrrsubdq0ya233pq99947L730Uu6+++488cQT6datW5LkwgsvzI477pizzz477du3zw033JDZs2fn6quvTv369bPOOutk7NixOffcc2s0rQtDMgoAAFCmrkdzv+6Y7pd54403Mn78+PTq1at6rWnTpunevXtGjRqVJBk1alSaNWtW3YgmSa9evVJRUZHRo0dXn9OzZ8/Ur1+/+pw+ffpk3Lhx+eCDDxapJskoAADAEmrWrFmZNWtWjbXKyspUVlYu0nXGjx+fJGnTpk2N9TZt2lQfGz9+fFq3bl3j+PLLL58WLVrUOKdz587zXePzY82bN1/omiSjAAAAS6jBgwenadOmNR6DBw+u67JqhWQUAACgTG2Ox35Txx13XAYOHFhjbVFT0SRp27ZtkmTChAlp165d9fqECRPStWvX6nMmTpxY43mffvpppkyZUv38tm3bZsKECTXO+fznz89ZWJJRAACAJVRlZWWaNGlS4/F1mtHOnTunbdu2GTFiRPXa9OnTM3r06PTo0SNJ0qNHj0ydOjVjxoypPmfkyJGZN29eunfvXn3OQw89lDlz5lSfM3z48Ky55pqLNKKbaEYBAACWCTNmzMjYsWMzduzYJJ9tWjR27Ni8/fbbKZVKOfzww3Paaafl73//e5577rnsv//+ad++ffr27Zsk6dKlS7bffvv87Gc/y+OPP55HHnkkAwYMyN5775327dsnSfbZZ5/Ur18/Bx10UF544YXcdNNNueCCC+ZLbxeGMV0AAIAyS9KY7qJ48skns/XWW1f//HmD2K9fv1x77bX59a9/nZkzZ+bggw/O1KlTs/nmm+fuu+9OgwYNqp9zww03ZMCAAdl2221TUVGRPfbYI0OGDKk+3rRp09x7773p379/Ntpoo7Rq1SonnnjiIt/WJUlKVVVVVd/g/S6Rvnv03XVdArAY3HLY5nVdArCYrN52xbouAVgMGiyl0VfTH11f1yVUm/bH/eq6hMVmKf3jAQAAsJgsncHoUsd3RgEAACicZJQlTkUp+VXv1bPLhu2zUuPKTJw+K3978p1cfN9rNc5brXWjHL3jmvn+qs2z3HKlvDphZgZc93Tem/rJfNe88qCNsuVaK+UX1z6V+16YON9xYPH7241X57GH7887b7+Z+pWVWXPt72W/g3+VlVfpVH3OvXf8LQ+PvDuvv/JyPv5oZq677YE0WrHxfNca89g/85frr8hbr7+aevXrZ+3vbZhjTz23wHcDLIoxTz6Ra6++Ki+9+HwmTZqU84ZcnG227VXXZQF1TDPKEufgrVfNj3p0yDF/ei6vTJiR9b7TJIP3Wi8ffvxprnvkrSRJh5YN88dfds9fn/hPhtz7SmbM+jSrt1kxs+bMm+96B2zRMcveN6Nh6fPCs09l+13+L6uvtU7mzZ2bG666KIN+3T8XXP3XNGjYMEkye9Yn6bpxj3TduEduuPKiBV5n1EMjMvTc07LPQf2zXteNM3fu3Lz95qtFvhVgEX388UdZc80103f3PTLwsAF1XQ58paV1A6OljWaUJc6GHZtlxAsT88DLk5Ik73zwcXbeoF2+16Fp8shn5xyx/Rp58OVJOevOf1U/7+33P57vWl3aN85BPTtntyGPZtSJ2xRSP7BgJ/yuZnM54Nen5Cd79Mprr7yUdb63YZJk5z32SZI8P/bJBV5j7txPc/XFZ2e/gw9Lrx37Vq+v0mnVxVM0UCs232LLbL7FlnVdBrCEqdNmdPLkybn66qszatSojB8/PknStm3bbLrppjnggAOy0kor1WV51JGn3pqaH3ZfJZ1arZA3J3+Utdo1zkadmmfw7S8nSUqlZKu1VsqVD76Rq3/aLWuv3Dj/mfJxho58vcYIboN6FTl3n/Vz8q0vZvKHs+vq7QBf4KOZM5IkjRs3WejnvP7Ky5kyeWIqKipy1M/3yQdTJqfzamtm/58flg6dV19cpQIAi0GdbWD0xBNPZI011siQIUPStGnT9OzZMz179kzTpk0zZMiQrLXWWnnyyQX/Zpxl22X3v547x76Xe47eIi/+rnduO3zTXPvPt/L3p99LkrRcsX5WbLB8Dt66cx4aNykHXvFk7n1+Qi7ef4N8f9Xm1df57S5d8tSbH2SE74jCEmfevHm55uKzs9a66y9SEznh3XeSJDcNuyx77HtQfnP6BWnUuHFOHHhwPpw+bXGVC8C3TKlUWmIey7I6S0YPPfTQ/N///V+GDh0634dcVVWVQw45JIceemhGjRr1pdeZNWtWZs2aVfP5n85Oafn6tV4zxdjxe22zy4btMvDGZ/LKhBnp0r5JfrvLWpk4/ZPcMubdVPz/Py8jXpiYa//52XdIX3r3w2zYsXl+tEmHPP76B9lm7ZWyyWotsuv5j9blWwG+wBVDfpe333wtp19w1SI9r6rqs++F77HvQenRc9skyYCjT87Be++QUQ/el94/2KPWawUAFo86a0afeeaZXHvttQvs9kulUo444ohssMEGX3mdwYMH55RTTqmx1rzHvmm52Y9rrVaKdczOa+ay+9/Inc98Nrr9r/EzsnLzBvn5NqvmljHv5oOZszNn7ry8OmFGjee9NnFGNur8WTLaY/WW6dByhYwZtG2Ncy7af4M8+cYH+fHQx4t5M8B8rhhyZsY89nBOPe+KtFypzSI9t1mLVkmSVTp2rl6rV79+2rRbOZMmjq/VOgGAxavOmtG2bdvm8ccfz1prrbXA448//njatPnq/0g57rjjMnDgwBprG570QG2USB1pUG+5VP3P9rdz56U6EZ0ztyrP/XtaOq/UqMY5nVZqlHc/+GwTo8vufz1/Hv2fGsfvOmrznPH3lzPyRWO7UBeqqqpy5YVn5fGH788p516eNu1WXuRrrLZGl9SrVz/v/PutdFnvs19YfvrpnEwc/15WatOutksG4FtqWR+PXVLUWTN61FFH5eCDD86YMWOy7bbbVjeeEyZMyIgRI3LFFVfk7LPP/srrVFZWprKyssaaEd2l2/0vTcovtlkt737wSV6ZMCNrr9w4P+nZKX994r/N5ZUPvpHz9+2aJ17/II+9NiU912yVbbqsVJ14Tv5w9gI3LXp36sf5zwfz77oLLH5XDPld/jni7hx76rlpuMIK+WDK5CTJCo1WTGVlgyTJB1MmZ+qU9zP+nX8nSd56/dU0XGGFtGrdNo2bNM0KjVZM7x/skZuGXZZWrdtkpTbtcttN1yVJNt3SPQthSfXRzJl5++23q39+5z//ycsvvZSmTZumXfv2dVgZUJdKVf8bQRXopptuynnnnZcxY8Zk7ty5SZLlllsuG220UQYOHJi99trra133u0ffXZtlUrBGlcvl8D7fzXbrtknLFetn4vRZuePp93LRfa9mztz//nHdc+OV8/OtV03bZg3yxqSZueDeV790s6JXfr99fnHtUzV23GXpcsthm9d1CXwDe2y70QLX+x99UrbZfpckn21M9OfrLv/Scz79dE5uuPKiPDj8rsyePSvfXWvdHNj/yHTotNriK57FbvW2K9Z1CSxGTzw+Oj89cP/51nfZdbecesbv6qAiitJgKb2RZMv9/1jXJVR7/7of1XUJi02dNqOfmzNnTiZP/uw35K1atUq9evW+0fU0o7Bs0ozCskszCssmzeg3tyw3o0vEH4969eqlXTvf9QEAAPi2WCKaUQAAgCWG/YsKUVHXBQAAAPDtoxkFAACgcMZ0AQAAyrjPaDEkowAAABROMwoAAEDhjOkCAACUMaZbDMkoAAAAhZOMAgAAlJGMFkMyCgAAQOE0owAAABTOmC4AAEA5U7qFkIwCAABQOM0oAAAAhTOmCwAAUMZuusWQjAIAAFA4zSgAAACFM6YLAABQxphuMSSjAAAAFE4yCgAAUEYyWgzJKAAAAIXTjAIAAFA4Y7oAAABljOkWQzIKAABA4TSjAAAAFM6YLgAAQDlTuoWQjAIAAFA4zSgAAACFM6YLAABQxm66xZCMAgAAUDjJKAAAQBnJaDEkowAAABROMwoAAEDhjOkCAACUMaZbDMkoAAAAhdOMAgAAUDhjugAAAOVM6RZCMgoAAEDhNKMAAAAUzpguAABAGbvpFkMyCgAAQOEkowAAAGUko8WQjAIAAFA4zSgAAACFM6YLAABQxphuMSSjAAAAFE4zCgAAQOGM6QIAAJQxplsMySgAAACF04wCAABQOGO6AAAA5UzpFkIyCgAAQOEkowAAAGVsYFQMySgAAACF04wCAABQOGO6AAAAZYzpFkMyCgAAQOE0owAAABTOmC4AAEAZU7rFkIwCAABQOM0oAAAAhTOmCwAAUMZuusWQjAIAAFA4ySgAAEAZwWgxJKMAAAAUTjMKAABA4YzpAgAAlLGBUTEkowAAABROMwoAAEDhjOkCAACUMaVbDMkoAAAAhdOMAgAAUDhjugAAAGUqKszpFkEyCgAAQOEkowAAAGVsYFQMySgAAACF04wCAABQOGO6AAAAZUrmdAshGQUAAKBwmlEAAAAKZ0wXAACgjCndYkhGAQAAKJxmFAAAgMIZ0wUAAChjN91iSEYBAAAonGQUAACgjGS0GJJRAAAACqcZBQAAoHDGdAEAAMqY0i2GZBQAAIDCaUYBAAAonDFdAACAMnbTLYZkFAAAgMJpRgEAACicMV0AAIAypnSLIRkFAABYBsydOzcnnHBCOnfunIYNG2a11VbLqaeemqqqqupzqqqqcuKJJ6Zdu3Zp2LBhevXqlVdeeaXGdaZMmZJ99903TZo0SbNmzXLQQQdlxowZtV6vZhQAAKBMqVRaYh6L4swzz8yll16aiy66KC+99FLOPPPMnHXWWbnwwgurzznrrLMyZMiQDB06NKNHj06jRo3Sp0+ffPLJJ9Xn7LvvvnnhhRcyfPjw3HHHHXnooYdy8MEH19rn+zljugAAAMuARx99NLvuumt22mmnJEmnTp3yxz/+MY8//niSz1LR888/P8cff3x23XXXJMl1112XNm3a5NZbb83ee++dl156KXfffXeeeOKJdOvWLUly4YUXZscdd8zZZ5+d9u3b11q9klEAAIBlwKabbpoRI0bkX//6V5LkmWeeycMPP5wddtghSfLGG29k/Pjx6dWrV/VzmjZtmu7du2fUqFFJklGjRqVZs2bVjWiS9OrVKxUVFRk9enSt1isZBQAAKLMkbWA0a9aszJo1q8ZaZWVlKisr5zv32GOPzfTp07PWWmtlueWWy9y5c3P66adn3333TZKMHz8+SdKmTZsaz2vTpk31sfHjx6d169Y1ji+//PJp0aJF9Tm1RTIKAACwhBo8eHCaNm1a4zF48OAFnvvnP/85N9xwQ2688cY89dRTGTZsWM4+++wMGzas4KoXjmQUAABgCXXcccdl4MCBNdYWlIomydFHH51jjz02e++9d5JkvfXWy1tvvZXBgwenX79+adu2bZJkwoQJadeuXfXzJkyYkK5duyZJ2rZtm4kTJ9a47qeffpopU6ZUP7+2SEYBAADK1PUOuuWPysrKNGnSpMbji5rRjz76KBUVNVu85ZZbLvPmzUuSdO7cOW3bts2IESOqj0+fPj2jR49Ojx49kiQ9evTI1KlTM2bMmOpzRo4cmXnz5qV79+61+jlLRgEAAJYBP/jBD3L66aenQ4cOWWeddfL000/n3HPPzU9+8pMknzXZhx9+eE477bR897vfTefOnXPCCSekffv26du3b5KkS5cu2X777fOzn/0sQ4cOzZw5czJgwIDsvffetbqTbqIZBQAAWCZceOGFOeGEE/LLX/4yEydOTPv27fPzn/88J554YvU5v/71rzNz5swcfPDBmTp1ajbffPPcfffdadCgQfU5N9xwQwYMGJBtt902FRUV2WOPPTJkyJBar7dUVVVVVetXrWPfPfruui4BWAxuOWzzui4BWExWb7tiXZcALAYNltLo6/tnPFDXJVR7/Ddb1XUJi43vjAIAAFC4pfR3FQAAAItHaUm60egyTDIKAABA4TSjAAAAFM6YLgAAQBlTusVYJpvR+47duq5LABaDtXodWdclAIvJB09cVNclAFAwY7oAAAAUbplMRgEAAL4uu+kWQzIKAABA4TSjAAAAFM6YLgAAQBlTusWQjAIAAFA4ySgAAEAZGxgVQzIKAABA4TSjAAAAFM6YLgAAQBlTusWQjAIAAFA4zSgAAACFM6YLAABQxm66xZCMAgAAUDjNKAAAAIUzpgsAAFDGmG4xJKMAAAAUTjIKAABQRjBaDMkoAAAAhdOMAgAAUDhjugAAAGVsYFQMySgAAACF04wCAABQOGO6AAAAZUzpFkMyCgAAQOE0owAAABTOmC4AAEAZu+kWQzIKAABA4SSjAAAAZQSjxZCMAgAAUDjNKAAAAIUzpgsAAFCmwpxuISSjAAAAFE4zCgAAQOGM6QIAAJQxpVsMySgAAACF04wCAABQOGO6AAAAZUrmdAshGQUAAKBwklEAAIAyFYLRQkhGAQAAKJxmFAAAgMIZ0wUAAChjA6NiSEYBAAAonGYUAACAwhnTBQAAKGNKtxiSUQAAAAqnGQUAAKBwxnQBAADKlGJOtwiSUQAAAAonGQUAAChTIRgthGQUAACAwmlGAQAAKJwxXQAAgDIlNxothGQUAACAwmlGAQAAKJwxXQAAgDKmdIshGQUAAKBwmlEAAAAKZ0wXAACgTIU53UJIRgEAACicZBQAAKCMYLQYklEAAAAKpxkFAACgcMZ0AQAAypTM6RZCMgoAAEDhNKMAAAAUzpguAABAGVO6xZCMAgAAUDjNKAAAAIUzpgsAAFCmwpxuISSjAAAAFE4zCgAAQOGM6QIAAJQxpFsMySgAAACFk4wCAACUKdnAqBCSUQAAAAqnGQUAAKBwxnQBAADKVJjSLYRkFAAAgMJpRgEAACicMV0AAIAydtMthmQUAACAwmlGAQAAKJwxXQAAgDKmdIshGQUAAKBwklEAAIAyNjAqhmQUAACAwmlGAQAAKJwxXQAAgDIVpnQLIRkFAACgcJpRAAAACmdMFwAAoIzddIshGQUAAKBwmlEAAAAKZ0wXAACgjCHdYkhGAQAAKJxkFAAAoEyFDYwKIRkFAACgcJpRAAAACmdMFwAAoIwp3WJIRgEAACicZhQAAIDCfa1m9J///Gd+/OMfp0ePHnnnnXeSJNdff30efvjhWi0OAACgaKVSaYl5LMsWuRm9+eab06dPnzRs2DBPP/10Zs2alSSZNm1azjjjjFovEAAAgIXzzjvv5Mc//nFatmyZhg0bZr311suTTz5Zfbyqqionnnhi2rVrl4YNG6ZXr1555ZVXalxjypQp2XfffdOkSZM0a9YsBx10UGbMmFHrtS5yM3raaadl6NChueKKK1KvXr3q9c022yxPPfVUrRYHAADAwvnggw+y2WabpV69evnHP/6RF198Meecc06aN29efc5ZZ52VIUOGZOjQoRk9enQaNWqUPn365JNPPqk+Z999980LL7yQ4cOH54477shDDz2Ugw8+uNbrXeTddMeNG5eePXvOt960adNMnTq1NmoCAACoM0vrdOyZZ56ZVVZZJddcc031WufOnav/d1VVVc4///wcf/zx2XXXXZMk1113Xdq0aZNbb701e++9d1566aXcfffdeeKJJ9KtW7ckyYUXXpgdd9wxZ599dtq3b19r9S5yMtq2bdu8+uqr860//PDDWXXVVWulKAAAAJJZs2Zl+vTpNR6ff1Xyf/39739Pt27d8n//939p3bp1Nthgg1xxxRXVx994442MHz8+vXr1ql5r2rRpunfvnlGjRiVJRo0alWbNmlU3oknSq1evVFRUZPTo0bX63ha5Gf3Zz36Www47LKNHj06pVMq7776bG264IUcddVR+8Ytf1GpxAAAARasolZaYx+DBg9O0adMaj8GDBy+w7tdffz2XXnppvvvd7+aee+7JL37xi/zqV7/KsGHDkiTjx49PkrRp06bG89q0aVN9bPz48WndunWN48svv3xatGhRfU5tWeQx3WOPPTbz5s3Ltttum48++ig9e/ZMZWVljjrqqBx66KG1WhwAAMC32XHHHZeBAwfWWKusrFzgufPmzUu3bt2qN5bdYIMN8vzzz2fo0KHp16/fYq91US1yMloqlfLb3/42U6ZMyfPPP5/HHnsskyZNyqmnnro46gMAAPjWqqysTJMmTWo8vqgZbdeuXdZee+0aa126dMnbb7+d5LOvXCbJhAkTapwzYcKE6mNt27bNxIkTaxz/9NNPM2XKlOpzassiJ6Ofq1+//nxvFGrDs08/mb/ceG1eGfdSpkyelJMGn5/Nttym+vh1V16SB+67O5Mmjk+9evXy3TXXzgE/PzRd1vnefNeaPXt2fvWzffP6K+Ny6bV/zmprrFXkW4Fvtc02XC1H7N8rG67dIe1Wapq9jrg8tz/wbPXxXbdZPz/dc/Ns0KVDWjZrlO4/HJxn//VO9fEO7Vpk3F2DFnjtfY++Kn+77+mst8bKOerA7bJp19XSslmjvPXulFz514dz8R8fWNxvD/ga/nTjDRl2zVWZPHlS1lhzrRz7mxOy3vfm//cb6trSuoHRZpttlnHjxtVY+9e//pWOHTsm+Wwzo7Zt22bEiBHp2rVrkmT69OkZPXp09Vcue/TokalTp2bMmDHZaKONkiQjR47MvHnz0r1791qtd5Gb0a233vpLb746cuTIb1QQfPLJx1l19TXTZ+fdMui4I+Y7/p0OHTPgyN+kXfvvZNasT/K3m67PcYcfkmv/fEeaNW9R49wrLz43LVutlNdfGTffdYDFq1HDyjz3r3dy3W2jctO5828Hv0LD+nl07Gu5efhTufTEfec7/p8JH6RTr+NqrP1kj81yxP69cs8jLyRJNuiySiZN+TAHHj8s/xn/QTZZf9VcfPyPMnfevAy96aHF88aAr+Xuf9yVs88anONPOiXrrbd+brh+WH7x84Ny2x13p2XLlnVdHiwTjjjiiGy66aY544wzstdee+Xxxx/P5ZdfnssvvzzJZ1Ouhx9+eE477bR897vfTefOnXPCCSekffv26du3b5LPktTtt98+P/vZzzJ06NDMmTMnAwYMyN57712rO+kmX6MZ/byD/tycOXMyduzYPP/880vkHDJLn+/32CLf77HFFx7fpvdONX7++a+Ozt2335I3XvtXNui2SfX646P+mTGPj8qJZ5ybJ0Y9vNjqBRbs3kdezL2PvPiFx/945xNJPktAF2TevKpMeP/DGmu7bL1+bh7+VGZ+PDtJct1tj9U4/uY776f79zpn123W14zCEub6Yddk9z33St/d9kiSHH/SKXnooQdy699uzkE/q/37F8K30cYbb5xbbrklxx13XAYNGpTOnTvn/PPPz777/veXvr/+9a8zc+bMHHzwwZk6dWo233zz3H333WnQoEH1OTfccEMGDBiQbbfdNhUVFdljjz0yZMiQWq93kZvR8847b4HrJ598cmbMmPGNC4JFMWfOnNx121/TaMXGWXX1NavXP5jyfs7/3Sk5+XcXpLLsLxaw9NqgyyrputYqOeJ3f/7S85qu2CAfTP+ooKqAhTFn9uy89OILOehnP69eq6ioyCabbJpnn3m6DiuDBfuySdAl3c4775ydd975C4+XSqUMGjQogwYt+KswSdKiRYvceOONi6O8GhZ5A6Mv8uMf/zhXX311bV0uSfLvf/87P/nJT2r1miwbHnvkweyybffsvFW3/O1Pf8jvzr8sTZs1T/LZzXx/f9rx2anvXlmjyzp1XClQW/r17ZGXXn8vjz3zxhees8n6nbNn741y1c2PFFgZ8FU+mPpB5s6dO984bsuWLTN58uQ6qgqoa7XWjI4aNapGtFsbpkyZUn1PnC+yKDeBZdmx/oYb59Jhf8n5l12XbptsltNOOCofTHk/SXLrX27Mxx99lL33P6iOqwRqS4PKevnhDt0y7NZRX3jO2qu1y5/POzinX35XRjz2coHVAQBfxyKP6e6+++41fq6qqsp7772XJ598MieccMIiXevvf//7lx5//fXXv/IagwcPzimnnFJj7bCjf5sjjlm0Wli6NGy4Qlb+Toes/J0O6bLu+jlgr51z9x235Ef7/zRjxzyel55/Jjtt1a3Gc/of9KNs03vH/PqE0+uoauDr2q1X16zQoH5uuOPxBR5fa9W2ueuyQ3P1zY/mzCvvKbg64Ks0b9Y8yy23XN5///0a6++//35atWpVR1XBF6u1xI4vtcjNaNOmTWv8XFFRkTXXXDODBg1K7969F+laffv2TalUSlVV1Ree81Xz2gu6Cex4X1391qmaNy9zZn+2oUn/I47NAQcPqD72/uRJ+c0Rh+S3g87KWuusV1clAt/AAX03zZ0PPpfJH8z/f/BdVm2bf1z+q9xw++icfPHtdVAd8FXq1a+fLmuvk9GPjco22/ZKksybNy+jR4/K3j/6cR1XB9SVRWpG586dmwMPPDDrrbdemjdv/o1fvF27drnkkkuy6667LvD42LFjq+9t80UqKyvnu+nrB3OM6S7NPv7oo7z7n7erfx7/3jt57V8vp3GTpmnctGn+OOyK9Nh8q7RouVKmTZua22/+UyZPnpie23z2y5DWbdvVuF7DFVZIkrRfeZWs1Lp2b9QLfLFGDetntVVWqv6508ot8701Vs4H0z/Kv8d/kOZNVsgqbZunXevPfsm5Rqc2SZIJ70+vsYvuqqu0yuYbrpa+h14632usvVq7/OPyX+W+R1/KkD+MTJuWjZMkc+dVLbBxBerOfv0OzAm/OSbrrLNu1l3ve/nD9cPy8ccfp+9uu3/1k6FgS/MGRkuTRWpGl1tuufTu3TsvvfRSrTSjG220UcaMGfOFzehXpaYsm/718gs5esB/v+952ZDfJ0m223GXHHb0Cfn3W29m+F1HZvq0D9K4abOsudY6OfeSa9Np1dXrqmRgATZcu2PuvfKw6p/POuqz2zlc//fHcvBJf8hOW66XKwbtV338+jM/27DutKF35fTL7qpe77drj7wzYWruGzX/90B367VBWrdonH12/n722fn71etvvft+1trppFp/T8DXt/0OO+aDKVNyyUVDMnnypKy5VpdcctmVaWlMF761SlWL2O1169YtZ555Zrbddttv/OL//Oc/M3PmzGy//fYLPD5z5sw8+eST2XLLLRfpum+9LxmFZdFavY6s6xKAxeSDJy6q6xKAxaDBIn8pcMnwq1uXnI3whvRdq65LWGwW+Y/HaaedlqOOOiqnnnpqNtpoozRq1KjG8SZNmiz0tbbYYosvPd6oUaNFbkQBAAC+iQpTuoVY6GZ00KBBOfLII7PjjjsmSXbZZZcas9RVVVUplUqZO3du7VcJAADAMmWhm9FTTjklhxxySO6///7FWQ8AAADfAgvdjH7+1VJjswAAwLLMmG4xFul+rrY4BgAAoDYs0gZGa6yxxlc2pFOmTPlGBQEAALDsW6Rm9JRTTknTpk0XVy0AAAB1zkRoMRapGd17773TunXrxVULAAAA3xIL3Yz67QAAAPBtYAOjYiz0Bkaf76YLAAAA39RCJ6Pz5s1bnHUAAADwLbJI3xkFAABY1vmGYjEW6T6jAAAAUBs0owAAABTOmC4AAECZCnO6hZCMAgAAUDjNKAAAAIUzpgsAAFBGYlcMnzMAAACFk4wCAACUsX9RMSSjAAAAFE4zCgAAQOGM6QIAAJRxn9FiSEYBAAAonGYUAACAwhnTBQAAKGNKtxiSUQAAAAqnGQUAAKBwxnQBAADKVBjTLYRkFAAAgMJJRgEAAMq4z2gxJKMAAAAUTjMKAABA4YzpAgAAlDGlWwzJKAAAAIXTjAIAAFA4Y7oAAABl3Ge0GJJRAAAACqcZBQAAoHDGdAEAAMqUYk63CJJRAAAACicZBQAAKGMDo2JIRgEAACicZhQAAIDCGdMFAAAoY0y3GJJRAAAACqcZBQAAoHDGdAEAAMqUSuZ0iyAZBQAAoHCaUQAAAApnTBcAAKCM3XSLIRkFAACgcJJRAACAMvYvKoZkFAAAgMJpRgEAACicMV0AAIAyFeZ0CyEZBQAAoHCaUQAAAApnTBcAAKCM+4wWQzIKAABA4TSjAAAAFM6YLgAAQBmb6RZDMgoAAEDhJKMAAABlKiIaLYJkFAAAgMJpRgEAACicMV0AAIAyNjAqhmQUAACAwmlGAQAAKJwxXQAAgDIVxnQLIRkFAACgcJpRAAAACmdMFwAAoEyF7XQLIRkFAACgcJJRAACAMoLRYkhGAQAAKJxmFAAAgMIZ0wUAAChjA6NiSEYBAAAonGYUAACAwhnTBQAAKGNKtxiSUQAAAAqnGQUAAKBwxnQBAADKSOyK4XMGAACgcJJRAACAMiU7GBVCMgoAAEDhNKMAAAAUzpguAABAGUO6xZCMAgAAUDjNKAAAAIUzpgsAAFCmwm66hZCMAgAAUDjNKAAAAIUzpgsAAFDGkG4xJKMAAAAUTjIKAABQxv5FxZCMAgAAUDjNKAAAAIUzpgsAAFCmZE63EJJRAAAACqcZBQAAoHCaUQAAgDIVS9Djm/jd736XUqmUww8/vHrtk08+Sf/+/dOyZcusuOKK2WOPPTJhwoQaz3v77bez0047ZYUVVkjr1q1z9NFH59NPP/2G1cxPMwoAALCMeeKJJ3LZZZfle9/7Xo31I444Irfffnv+8pe/5MEHH8y7776b3Xffvfr43Llzs9NOO2X27Nl59NFHM2zYsFx77bU58cQTa71GzSgAAMAyZMaMGdl3331zxRVXpHnz5tXr06ZNy1VXXZVzzz0322yzTTbaaKNcc801efTRR/PYY48lSe699968+OKL+cMf/pCuXbtmhx12yKmnnpqLL744s2fPrtU6NaMAAABlSqXSEvOYNWtWpk+fXuMxa9asL62/f//+2WmnndKrV68a62PGjMmcOXNqrK+11lrp0KFDRo0alSQZNWpU1ltvvbRp06b6nD59+mT69Ol54YUXavFT1owCAAAssQYPHpymTZvWeAwePPgLz//Tn/6Up556aoHnjB8/PvXr10+zZs1qrLdp0ybjx4+vPqe8Ef38+OfHapP7jAIAAJRZku4yetxxx2XgwIE11iorKxd47r///e8cdthhGT58eBo0aFBEed+IZBQAAGAJVVlZmSZNmtR4fFEzOmbMmEycODEbbrhhll9++Sy//PJ58MEHM2TIkCy//PJp06ZNZs+enalTp9Z43oQJE9K2bdskSdu2befbXffznz8/p7ZoRgEAAJYB2267bZ577rmMHTu2+tGtW7fsu+++1f+7Xr16GTFiRPVzxo0bl7fffjs9evRIkvTo0SPPPfdcJk6cWH3O8OHD06RJk6y99tq1Wq8xXQAAgDKl0pI0qLvwGjdunHXXXbfGWqNGjdKyZcvq9YMOOigDBw5MixYt0qRJkxx66KHp0aNHNtlkkyRJ7969s/baa2e//fbLWWedlfHjx+f4449P//79vzCR/bo0owAAAN8S5513XioqKrLHHntk1qxZ6dOnTy655JLq48stt1zuuOOO/OIXv0iPHj3SqFGj9OvXL4MGDar1WkpVVVVVtX7VOvbRnGXuLQFJSkvUdgJAbZr20Zy6LgFYDNo2rVfXJXwtf33mvbouodqe67er6xIWG8koAABAGRvrFMPnDAAAQOE0owAAABTOmC4AAECZpXU33aWNZBQAAIDCSUYBAADKyEWLIRkFAACgcJpRAAAACmdMFwAAoIz9i4ohGQUAAKBwmlEAAAAKZ0wXAACgTIX9dAshGQUAAKBwmlEAAAAKZ0wXAACgjN10iyEZBQAAoHCSUQAAgDIlGxgVQjIKAABA4TSjAAAAFM6YLgAAQBkbGBVDMgoAAEDhNKMAAAAUzpguAABAmQq76RZCMgoAAEDhNKMAAAAUzpguAABAGbvpFkMyCgAAQOEkowAAAGUko8WQjAIAAFA4zSgAAACFM6YLAABQpuQ+o4WQjAIAAFA4zSgAAACFM6YLAABQpsKUbiEkowAAABROMwoAAEDhjOkCAACUsZtuMSSjAAAAFE4yCgAAUKYkGC2EZBQAAIDCaUYBAAAonDFdAACAMjYwKoZkFAAAgMJpRgEAACicMV0AAIAyFaZ0CyEZBQAAoHCaUQAAAApnTBcAAKCM3XSLIRkFAACgcJJRAACAMiXBaCEkowAAABROMwoAAEDhjOkCAACUMaVbDMkoAAAAhdOMAgAAUDhjugAAAGUqbKdbCMkoAAAAhdOMAgAAUDhjugAAAGUM6RZDMgoAAEDhJKMAAADlRKOFkIwCAABQOM0oAAAAhTOmCwAAUKZkTrcQklEAAAAKpxkFAACgcMZ0AQAAypRM6RZCMgoAAEDhNKMAAAAUzpguAABAGVO6xZCMAgAAUDjJKAAAQDnRaCEkowAAABROMwoAAEDhjOkCAACUKZnTLYRkFAAAgMJpRgEAACicMV0AAIAyJVO6hZCMAgAAUDjNKAAAAIUzpgsAAFDGlG4xJKMAAAAUTjIKAABQTjRaCMkoAAAAhdOMAgAAUDhjugAAAGVK5nQLIRkFAACgcJpRAAAACmdMFwAAoEzJlG4hJKMAAAAUTjMKAABA4YzpAgAAlDGlWwzJKAAAAIWTjAIAAJQTjRZCMgoAAEDhNKMAAAAUzpguAABAmZI53UJIRgEAACicZhQAAIDCGdMFAAAoUzKlWwjJKAAAAIXTjAIAAFA4Y7oAAABlTOkWQzIKAABA4SSjAAAA5USjhZCMAgAAUDjNKAAAAIUzpgsAAFCmZE63EJJRAAAACqcZBQAAWAYMHjw4G2+8cRo3bpzWrVunb9++GTduXI1zPvnkk/Tv3z8tW7bMiiuumD322CMTJkyocc7bb7+dnXbaKSussEJat26do48+Op9++mmt16sZZakw5sknclj/Q7Ld1ltkg3XXyv0j7qtxvKqqKpdcNCTbbbVFNtlo/fz8pwfmrbferJtiga9th97bpOu6a873OOO0U+q6NGARfDRzZi4893fZa5ftst0WG+WXB+2bl158rvr4lPcnZ/Apv83uO26d3lt0y9G/+nn+8/ZbdVgx1FQqLTmPRfHggw+mf//+eeyxxzJ8+PDMmTMnvXv3zsyZM6vPOeKII3L77bfnL3/5Sx588MG8++672X333auPz507NzvttFNmz56dRx99NMOGDcu1116bE088sbY+3mqlqqqqqlq/ah37aM4y95a+9R7+50N55umn0mXtdXLk4Yfm3Asuytbb9qo+fs1VV+TqKy/PoNN/l5VX/k4uueiCvPrKv3LzbXemsrKyDiunNvn+xrJvypQpmTdvbvXPr77ySg752YG54urrsvH3u9dhZSxu0z6aU9clUItO/s2ReeO1VzPwmBPScqXWGf6P2/OXP16fYTfdllYrtc4vD/pxll9++fzy8KPSqNGK+fON1+XxUQ9n2E23pWHDFeq6fGpR26b16rqEr+XFd2d+9UkFWbt9o6/93EmTJqV169Z58MEH07Nnz0ybNi0rrbRSbrzxxuy5555JkpdffjldunTJqFGjsskmm+Qf//hHdt5557z77rtp06ZNkmTo0KE55phjMmnSpNSvX79W3lciGWUpsfkWPdP/V4dnm17bzXesqqoqN15/XX528CHZeptts8aaa+bUM87MpIkT50tQgSVbixYt0qrVStWPhx68P6us0iHdNv5+XZcGLKRZn3ySh+6/L4ccOjDrb9gt31mlQw48uH9WXqVDbrv5pvzn7bfy4vPPZOAxJ6TL2uulQ8fOGXjMCZk1a1ZG3HNXXZcPy5Rp06Yl+ezf1yQZM2ZM5syZk169/hvqrLXWWunQoUNGjRqVJBk1alTWW2+96kY0Sfr06ZPp06fnhRdeqNX6NKMs9d75z38yefKkdO+xafVa48aNs+73vpdnnxlbd4UB38icObNz1x1/z6677ZHSos4pAXVm7ty5mTt3burXrzmZVFlZmeeeeSqz58xOktSv/G+6UlFRkXr16uW5Z54utFb4IqUl6DFr1qxMnz69xmPWrFlf+R7mzZuXww8/PJtttlnWXXfdJMn48eNTv379NGvWrMa5bdq0yfjx46vPKW9EPz/++bHapBllqTd58qQkSYuWLWust2zZKu9PnlwXJQG1YOSI+/Lhhx9ml7671XUpwCJYoVGjrLPe+rnu6qGZPGli5s6dm3v/cXteeO6ZvD95cjp26pw2bdvl8osvyIfTp2XOnDm5cdhVmTRxQt7///+mA/81ePDgNG3atMZj8ODBX/m8/v375/nnn8+f/vSnAqr8euq8Gf3444/z8MMP58UXX5zv2CeffJLrrrvuS5//dX9TAMCS7da/3ZzNNu+Z1q3bfPXJwBLlt6cMTlVVssdO22S7zTfMzTfdkG1775BSRSnLL18vp555fv7z9pvZuddm6dOzW54e83i6b7pFShV1/p+m8Jm6jkPLHscdd1ymTZtW43Hcccd9afkDBgzIHXfckfvvvz/f+c53qtfbtm2b2bNnZ+rUqTXOnzBhQtq2bVt9zv/urvv5z5+fU1vq9G/8v/71r3Tp0iU9e/bMeuutly233DLvvfde9fFp06blwAMP/NJrLOg3BWef+dW/KWDZ0arVSkmSKe+/X2P9/fcnp2WrVnVREvANvfvuOxn92KPZbY8967oU4GtY+TsdMuSya3P3g4/nL7ffl8uu/VM+/fTTtF/5s/8oXrPLOrnqhptz58hR+dtd9+f3Qy7L9GlTq48D/1VZWZkmTZrUeHzRBp1VVVUZMGBAbrnllowcOTKdO3eucXyjjTZKvXr1MmLEiOq1cePG5e23306PHj2SJD169Mhzzz2XiRMnVp8zfPjwNGnSJGuvvXatvrc6bUaPOeaYrLvuupk4cWLGjRuXxo0bZ7PNNsvbb7+90NdY0G8Kjjrmy39TwLJl5e98J61arZTRj42qXpsxY0aef/bZfG/9rnVXGPC13XbL39KiRcts0XOrui4F+AYaNlwhLVutlA+nT8sTjz2azXpuU+P4iis2TrPmLfKft9/KuJdeyOY9t66jSmHZ0L9///zhD3/IjTfemMaNG2f8+PEZP358Pv744yRJ06ZNc9BBB2XgwIG5//77M2bMmBx44IHp0aNHNtlkkyRJ7969s/baa2e//fbLM888k3vuuSfHH398+vfvX+t3qVi+Vq+2iB599NHcd999adWqVVq1apXbb789v/zlL7PFFlvk/vvvT6NGX72NcWVl5Xwfilu7LHs++mhm/l32S4p33vlPxr38Upo0bZp27dpnn/32z5WXD02Hjp2y8sor55KLhmSl1q1r3P4FWDrMmzcvf7/1b/nBrn2z/PJ1+s8U8DU9PuqRVKUqHTp0yn/+83aGDjknHTp1zo4/6Jskuf++e9KsefO0adsur7/6Si4893fZfMttsvEmm9Vt4fD/La23k7v00kuTJFtttVWN9WuuuSYHHHBAkuS8885LRUVF9thjj8yaNSt9+vTJJZdcUn3ucsstlzvuuCO/+MUv0qNHjzRq1Cj9+vXLoEGDar3eOr3PaJMmTTJ69Oh06dKlxvqAAQNy22235cYbb8xWW22VuXPnfsEVFkwzuux58vHR+dlP+s23/oNd+2bQ6b9LVVVVLr34wvztL3/Ohx9OT9cNN8pvjj8xHTt1XsDVWFotrf8wsGgefeTh/PLnB+W2O+72d/hbxH1Gly0jh9+dKy45P5MmTkjjJk2z5Tbb5ae/+FVWXLFxkuSvN/0hf7r+mnww5f20bLVS+uy4S/Y/6JDUq7d03pOSL7a03mf05fc+qusSqq3Vbtm9926dNqPf//73c+ihh2a//fab79iAAQNyww03ZPr06ZpRIIlmFJZlmlFYNmlGv7lluRmt0++M7rbbbvnjH/+4wGMXXXRRfvSjH6UOe2UAAOBbqFRach7LsjpNRhcXySgsmySjsOySjMKyaWlNRseNX3KS0TXbSkYBAACg1timEAAAoIxZrGJIRgEAACicZBQAAKCcaLQQklEAAAAKpxkFAACgcMZ0AQAAyridXDEkowAAABROMwoAAEDhjOkCAACUKZnSLYRkFAAAgMJpRgEAACicMV0AAIAypnSLIRkFAACgcJJRAACAcqLRQkhGAQAAKJxmFAAAgMIZ0wUAAChTMqdbCMkoAAAAhdOMAgAAUDhjugAAAGVKpnQLIRkFAACgcJpRAAAACmdMFwAAoIwp3WJIRgEAACicZBQAAKCcaLQQklEAAAAKpxkFAACgcMZ0AQAAypTM6RZCMgoAAEDhNKMAAAAUzpguAABAmZIp3UJIRgEAACicZhQAAIDCGdMFAAAoY0q3GJJRAAAACicZBQAAKGMDo2JIRgEAACicZhQAAIDCGdMFAACowZxuESSjAAAAFE4zCgAAQOGM6QIAAJSxm24xJKMAAAAUTjMKAABA4YzpAgAAlDGlWwzJKAAAAIWTjAIAAJSxgVExJKMAAAAUTjMKAABA4YzpAgAAlCnZwqgQklEAAAAKpxkFAACgcMZ0AQAAypnSLYRkFAAAgMJpRgEAACicMV0AAIAypnSLIRkFAACgcJJRAACAMiXRaCEkowAAABROMwoAAEDhjOkCAACUKdnCqBCSUQAAAAqnGQUAAKBwxnQBAADKmdIthGQUAACAwmlGAQAAKJwxXQAAgDKmdIshGQUAAKBwklEAAIAyJdFoISSjAAAAFE4zCgAAQOGM6QIAAJQp2cKoEJJRAAAACqcZBQAAoHDGdAEAAMrYTbcYklEAAAAKpxkFAACgcJpRAAAACqcZBQAAoHA2MAIAAChjA6NiSEYBAAAonGYUAACAwhnTBQAAKFOKOd0iSEYBAAAonGYUAACAwhnTBQAAKGM33WJIRgEAACicZhQAAIDCGdMFAAAoY0q3GJJRAAAACicZBQAAKCcaLYRkFAAAgMJpRgEAACicMV0AAIAyJXO6hZCMAgAAUDjNKAAAAIUzpgsAAFCmZEq3EJJRAAAACqcZBQAAoHDGdAEAAMqY0i2GZBQAAIDCSUYBAADKiUYLIRkFAACgcJpRAAAACmdMFwAAoEzJnG4hJKMAAADLkIsvvjidOnVKgwYN0r179zz++ON1XdICaUYBAACWETfddFMGDhyYk046KU899VTWX3/99OnTJxMnTqzr0uZTqqqqqqrrImrbR3OWubcExMgMLMumfTSnrksAFoO2TevVdQlfyyef1nUF/9VgEb9Y2b1792y88ca56KKLkiTz5s3LKquskkMPPTTHHnvsYqjw65OMAgAALANmz56dMWPGpFevXtVrFRUV6dWrV0aNGlWHlS2YDYwAAACWULNmzcqsWbNqrFVWVqaysnK+cydPnpy5c+emTZs2NdbbtGmTl19+ebHW+XUsk83oCvWM8n1bzJo1K4MHD85xxx23wL+QwNLJ3+1vn4ZL6Sgfi8bfbZYWizoauzidfNrgnHLKKTXWTjrppJx88sl1U1AtWia/M8q3x/Tp09O0adNMmzYtTZo0qetygFri7zYsm/zdhkW3KMno7Nmzs8IKK+Svf/1r+vbtW73er1+/TJ06NbfddtviLneR+M4oAADAEqqysjJNmjSp8fiiyYL69etno402yogRI6rX5s2blxEjRqRHjx5FlbzQlqAAGgAAgG9i4MCB6devX7p165bvf//7Of/88zNz5swceOCBdV3afDSjAAAAy4gf/vCHmTRpUk488cSMHz8+Xbt2zd133z3fpkZLAs0oS7XKysqcdNJJNkGAZYy/27Bs8ncbijFgwIAMGDCgrsv4SjYwAgAAoHA2MAIAAKBwmlEAAAAKpxkFAACgcJpRlloXX3xxOnXqlAYNGqR79+55/PHH67ok4Bt66KGH8oMf/CDt27dPqVTKrbfeWtclAbVg8ODB2XjjjdO4ceO0bt06ffv2zbhx4+q6LKCOaUZZKt10000ZOHBgTjrppDz11FNZf/3106dPn0ycOLGuSwO+gZkzZ2b99dfPxRdfXNelALXowQcfTP/+/fPYY49l+PDhmTNnTnr37p2ZM2fWdWlAHbKbLkul7t27Z+ONN85FF12UJJk3b15WWWWVHHrooTn22GPruDqgNpRKpdxyyy3p27dvXZcC1LJJkyaldevWefDBB9OzZ8+6LgeoI5JRljqzZ8/OmDFj0qtXr+q1ioqK9OrVK6NGjarDygCAhTFt2rQkSYsWLeq4EqAuaUZZ6kyePDlz585NmzZtaqy3adMm48ePr6OqAICFMW/evBx++OHZbLPNsu6669Z1OUAdWr6uCwAA4Nujf//+ef755/Pwww/XdSlAHdOMstRp1apVlltuuUyYMKHG+oQJE9K2bds6qgoA+CoDBgzIHXfckYceeijf+c536rocoI4Z02WpU79+/Wy00UYZMWJE9dq8efMyYsSI9OjRow4rAwAWpKqqKgMGDMgtt9ySkSNHpnPnznVdErAEkIyyVBo4cGD69euXbt265fvf/37OP//8zJw5MwceeGBdlwZ8AzNmzMirr75a/fMbb7yRsWPHpkWLFunQoUMdVgZ8E/3798+NN96Y2267LY0bN67e46Fp06Zp2LBhHVcH1BW3dmGpddFFF+X3v/99xo8fn65du2bIkCHp3r17XZcFfAMPPPBAtt566/nW+/Xrl2uvvbb4goBaUSqVFrh+zTXX5IADDii2GGCJoRkFAACgcL4zCgAAQOE0owAAABROMwoAAEDhNKMAAAAUTjMKAABA4TSjAAAAFE4zCgAAQOE0owAAABROMwpAnTvggAPSt2/f6p+32mqrHH744YXX8cADD6RUKmXq1KmFvzYAfNtoRgH4QgcccEBKpVJKpVLq16+f1VdfPYMGDcqnn366WF/3b3/7W0499dSFOlcDCQBLp+XrugAAlmzbb799rrnmmsyaNSt33XVX+vfvn3r16uW4446rcd7s2bNTv379WnnNFi1a1Mp1AIAll2QUgC9VWVmZtm3bpmPHjvnFL36RXr165e9//3v1aO3pp5+e9u3bZ80110yS/Pvf/85ee+2VZs2apUWLFtl1113z5ptvVl9v7ty5GThwYJo1a5aWLVvm17/+daqqqmq85v+O6c6aNSvHHHNMVllllVRWVmb11VfPVVddlTfffDNbb711kqR58+YplUo54IADkiTz5s3L4MGD07lz5zRs2DDrr79+/vrXv9Z4nbvuuitrrLFGGjZsmK233rpGnQDA4qUZBWCRNGzYMLNnz06SjBgxIuPGjcvw4cNzxx13ZM6cOenTp08aN26cf/7zn3nkkUey4oorZvvtt69+zjnnnJNrr702V199dR5++OFMmTIlt9xyy5e+5v77758//vGPGTJkSF566aVcdtllWXHFFbPKKqvk5ptvTpKMGzcu7733Xi644IIkyeDBg3Pddddl6NCheeGFF3LEEUfkxz/+cR588MEknzXNu+++e37wgx9k7Nix+elPf5pjjz12cX1sAMD/MKYLwEKpqqrKiBEjcs899+TQQw/NpEmT0qhRo1x55ZXV47l/+MMfMm/evFx55ZUplUpJkmuuuSbNmjXLAw88kN69e+f888/Pcccdl9133z1JMnTo0Nxzzz1f+Lr/+te/8uc//znDhw9Pr169kiSrrrpq9fHPR3pbt26dZs2aJfksST3jjDNy3333pUePHtXPefjhh3PZZZdlyy23zKWXXprVVlst55xzTpJkzTXXzHPPPZczzzyzFj81AOCLaEYB+FJ33HFHVlxxxcyZMyfz5s3LPvvsk5NPPjn9+/fPeuutV+N7os8880xeffXVNG7cuMY1Pvnkk7z22muZNm1a3nvvvXTv3r362PLLL59u3brNN6r7ubFjx2a55ZbLlltuudA1v/rqq/noo4+y3Xbb1VifPXt2NthggyTJSy+9VKOOJNWNKwCw+GlGAfhSW2+9dS699NLUr18/7du3z/LL//efjkaNGtU4d8aMGdloo41yww03zHedlVZa6Wu9fsOGDRf5OTNmzEiS3HnnnVl55ZVrHKusrPxadQAAtUszCsCXatSoUVZfffWFOnfDDTfMTTfdlNatW6dJkyYLPKddu3YZPXp0evbsmST59NNPM2bMmGy44YYLPH+99dbLvHnz8uCDD1aP6Zb7PJmdO3du9draa6+dysrKvP3221+YqHbp0iV///vfa6w99thjX/0mAYBaYQMjAGrNvvvum1atWmXXXXfNP//5z7zxxht54IEH8qtf/Sr/+c9/kiSHHXZYfve73+XWW2/Nyy+/nF/+8pdfeo/QTp06pV+/fvnJT36SW2+9tfqaf/7zn5MkHTt2TKlUyh133JFJkyZlxowZady4cY466qgcccQRGTZsWF577bU89dRTufDCCzNs2LAkySGHHJJXXnklRx99dMaNG5cbb7wx11577eL+iACA/08zCkCtWWGFFfLQQw+lQ4cO2X333dOlS5ccdNBB+eSTT6qT0iOPPDL77bdf+vXrlx49eqRx48bZbbfdvvS6l156afbcc8/88pe/zFprrZWf/exnmTlzZpJk5ZVXzimnnJJjjz02bdq0yYABA5Ikp556ak444YQMHjw4Xbp0yfbbb58777wznTt3TpJ06NAhN998c2699dasv/76GTp0aM4444zF+OkAAOVKVV+0YwQAAAAsJpJRAAAACqcZBQAAoHCaUQAAAAqnGQUAAKBwmlEAAAAKpxkFAACgcJpRAAAACqcZBQAAoHCaUQAAAAqnGQUAAKBwmlEAAAAKpxkFAACgcP8PoYY39DxX9zsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "test_df = test_df[['generated', 'Hierarchy_Label']]\n",
    "test_df.loc[:, 'generated'] = test_df['generated'].astype(str)\n",
    "test_df.loc[:, 'Hierarchy_Label'] = test_df['Hierarchy_Label'].astype(str)\n",
    "\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "confidences = []\n",
    "texts = []\n",
    "\n",
    "for index, row in tqdm(test_df.iterrows(), total=test_df.shape[0]):\n",
    "    text = row['generated']\n",
    "    true_label = row['Hierarchy_Label']\n",
    "    predicted_label, confidence = predict_label(text)\n",
    "\n",
    "    texts.append(text)\n",
    "    true_labels.append(true_label)\n",
    "    predicted_labels.append(predicted_label)\n",
    "    confidences.append(confidence)\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_labels, predicted_labels, digits=4))\n",
    "\n",
    "# Optional: Confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Store results if needed\n",
    "results_df = pd.DataFrame({\n",
    "    'Text': texts,\n",
    "    'True_Label': true_labels,\n",
    "    'Predicted_Label': predicted_labels,\n",
    "    'Confidence': confidences\n",
    "})\n",
    "\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig('genz_confusion_matrix.png')\n",
    "print(\"Confusion matrix saved as 'confusion_matrix.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2503 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2503/2503 [01:45<00:00, 23.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21135, 14337, 22163, 3848, 18353]\n",
      "[2905, 4744, 13620, 7516, 12281]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# write code that will find the index of the datapoint which predicts the normal label correctly but genz wrongly\n",
    "\n",
    "\n",
    "test_df = test_df[['original', 'generated', 'Hierarchy_Label', 'id']]\n",
    "test_df.loc[:, 'original'] = test_df['original'].astype(str)\n",
    "test_df.loc[:, 'generated'] = test_df['generated'].astype(str)\n",
    "test_df.loc[:, 'Hierarchy_Label'] = test_df['Hierarchy_Label'].astype(str)\n",
    "test_df.loc[:, 'id'] = test_df['id'].astype(int)\n",
    "\n",
    "listA = []\n",
    "listB = []\n",
    "\n",
    "for index, row in tqdm(test_df.iterrows(), total=test_df.shape[0]):\n",
    "    normal = row['original']\n",
    "    genz = row['generated']\n",
    "    true_label = row['Hierarchy_Label']\n",
    "\n",
    "    predicted_label, confidence = predict_label(normal)\n",
    "    predicted_genz_label, confidence = predict_label(genz)\n",
    "    if predicted_label == true_label and predicted_genz_label != true_label:\n",
    "        listA.append(row['id'])\n",
    "\n",
    "    if predicted_genz_label == true_label and predicted_label != true_label:\n",
    "        listB.append(row['id'])\n",
    "\n",
    "\n",
    "print(listA[:5])\n",
    "print(listB[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 938.00 MiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39msoftmax(outputs\u001b[38;5;241m.\u001b[39mlogits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Explain one example\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m explanation1 \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_instance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest_original_df[\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moriginal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m][0]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclassifier_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\n\u001b[1;32m     29\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Show explanation\u001b[39;00m\n\u001b[1;32m     32\u001b[0m explanation1\u001b[38;5;241m.\u001b[39mshow_in_notebook()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/lime/lime_text.py:413\u001b[0m, in \u001b[0;36mLimeTextExplainer.explain_instance\u001b[0;34m(self, text_instance, classifier_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001b[0m\n\u001b[1;32m    406\u001b[0m indexed_string \u001b[38;5;241m=\u001b[39m (IndexedCharacters(\n\u001b[1;32m    407\u001b[0m     text_instance, bow\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbow, mask_string\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_string)\n\u001b[1;32m    408\u001b[0m                   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchar_level \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[1;32m    409\u001b[0m                   IndexedString(text_instance, bow\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbow,\n\u001b[1;32m    410\u001b[0m                                 split_expression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_expression,\n\u001b[1;32m    411\u001b[0m                                 mask_string\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_string))\n\u001b[1;32m    412\u001b[0m domain_mapper \u001b[38;5;241m=\u001b[39m TextDomainMapper(indexed_string)\n\u001b[0;32m--> 413\u001b[0m data, yss, distances \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__data_labels_distances\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexed_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistance_metric\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(yss[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/lime/lime_text.py:482\u001b[0m, in \u001b[0;36mLimeTextExplainer.__data_labels_distances\u001b[0;34m(self, indexed_string, classifier_fn, num_samples, distance_metric)\u001b[0m\n\u001b[1;32m    480\u001b[0m     data[i, inactive] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    481\u001b[0m     inverse_data\u001b[38;5;241m.\u001b[39mappend(indexed_string\u001b[38;5;241m.\u001b[39minverse_removing(inactive))\n\u001b[0;32m--> 482\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minverse_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    483\u001b[0m distances \u001b[38;5;241m=\u001b[39m distance_fn(sp\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39mcsr_matrix(data))\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data, labels, distances\n",
      "Cell \u001b[0;32mIn[2], line 21\u001b[0m, in \u001b[0;36mpredict_proba\u001b[0;34m(texts)\u001b[0m\n\u001b[1;32m     19\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 21\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39msoftmax(outputs\u001b[38;5;241m.\u001b[39mlogits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1562\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1554\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1555\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1560\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1562\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1563\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1565\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1568\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1570\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1572\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1574\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1576\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1020\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1011\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m   1013\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m   1014\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1015\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   1019\u001b[0m )\n\u001b[0;32m-> 1020\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1032\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1033\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:610\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    601\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    602\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    603\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    607\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    608\u001b[0m     )\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 610\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:537\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    534\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    535\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 537\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    540\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    542\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/pytorch_utils.py:237\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:549\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m--> 549\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    550\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:450\u001b[0m, in \u001b[0;36mBertIntermediate.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    449\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[0;32m--> 450\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate_act_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/activations.py:78\u001b[0m, in \u001b[0;36mGELUActivation.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 938.00 MiB. GPU "
     ]
    }
   ],
   "source": [
    "from lime.lime_text import LimeTextExplainer\n",
    "import numpy as np\n",
    "\n",
    "test_original_df = test_df[['original', 'Hierarchy_Label']]\n",
    "test_original_df.loc[:, 'original'] = test_original_df['original'].astype(str)\n",
    "test_original_df.loc[:, 'Hierarchy_Label'] = test_original_df['Hierarchy_Label'].astype(str)\n",
    "\n",
    "test_generated_df = test_df[['generated', 'Hierarchy_Label']]\n",
    "test_generated_df.loc[:, 'generated'] = test_generated_df['generated'].astype(str)\n",
    "test_generated_df.loc[:, 'Hierarchy_Label'] = test_generated_df['Hierarchy_Label'].astype(str)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "explainer = LimeTextExplainer(class_names=['Sender higher', 'Similar level', 'Recipient higher'])\n",
    "\n",
    "def predict_proba(texts):\n",
    "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return torch.softmax(outputs.logits, dim=1).cpu().detach().numpy()\n",
    "\n",
    "# Explain one example\n",
    "explanation1 = explainer.explain_instance(\n",
    "    text_instance=\"test_original_df['original'][0]\",\n",
    "    classifier_fn=predict_proba,\n",
    "    num_features=10\n",
    ")\n",
    "\n",
    "# Show explanation\n",
    "explanation1.show_in_notebook()\n",
    "\n",
    "# Save the explanation to a file\n",
    "explanation1.save_to_file(\"lime_explanation_original.html\")\n",
    "\n",
    "\n",
    "# Explain another example\n",
    "explanation2 = explainer.explain_instance(\n",
    "    text_instance=\"test_generated_df['generated'][0]\",\n",
    "    classifier_fn=predict_proba,\n",
    "    num_features=10\n",
    ")\n",
    "# Show explanation\n",
    "explanation2.show_in_notebook()\n",
    "# Save the explanation to a file\n",
    "explanation2.save_to_file(\"lime_explanation_generated.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
